{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " VAE Beta exp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Setting up google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "metadata": {
        "id": "87bvzlVH8tL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da700f82-9563-4226-87fe-c93c4000cabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaA4R5mm8bK1"
      },
      "outputs": [],
      "source": [
        "import models as models\n",
        "import five_fold_training\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.utils.data as data_utils\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from IPython import display\n",
        "import math\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import pickle\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/Data/MM_train_data'\n",
        "train_data = torch.load(train_path)\n",
        "test_path = '/content/drive/MyDrive/Data/MM_test_data'\n",
        "test_data = torch.load(test_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "iA6gl791C1Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ConcatDataset([test_data, train_data])"
      ],
      "metadata": {
        "id": "fOPgmgenDDNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net1_4 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128, \n",
        "      latent_size=4)"
      ],
      "metadata": {
        "id": "C4EWUYE1B9WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net1_15 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128,  \n",
        "      latent_size=15)"
      ],
      "metadata": {
        "id": "DqzWmtNGCUxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net1_25 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128, \n",
        "      latent_size=25)"
      ],
      "metadata": {
        "id": "0ACwWvJmCXqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net1_50 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128, \n",
        "      latent_size=50)"
      ],
      "metadata": {
        "id": "QNEqY-uVCaTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net1_100 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128, \n",
        "      latent_size=100)"
      ],
      "metadata": {
        "id": "nuEJCet8Cdzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net2_4 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128, \n",
        "      latent_size=4)"
      ],
      "metadata": {
        "id": "hj6g_wWHLQWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net2_15 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128,  \n",
        "      latent_size=15)"
      ],
      "metadata": {
        "id": "0P5Yxi7tLQWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net2_25 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128, \n",
        "      latent_size=25)"
      ],
      "metadata": {
        "id": "nzzuDAFKLQWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net2_50 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128, \n",
        "      latent_size=50)"
      ],
      "metadata": {
        "id": "6BDjP19rLQWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net2_100 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128, \n",
        "      latent_size=100)"
      ],
      "metadata": {
        "id": "Tjh0bhFULQWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net3_4 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128, \n",
        "      latent_size=4)"
      ],
      "metadata": {
        "id": "v6HZi2CALT_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net3_15 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128,  \n",
        "      latent_size=15)"
      ],
      "metadata": {
        "id": "7TfW4pQ3LT_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net3_25 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128, \n",
        "      latent_size=25)"
      ],
      "metadata": {
        "id": "lI1zZZhZLT_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net3_50 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128, \n",
        "      latent_size=50)"
      ],
      "metadata": {
        "id": "KIM2Sov7LT_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net3_100 = models.BernoulliVAE2(input_size=204, \n",
        "      hidden_size1=196, \n",
        "      hidden_size2=128, \n",
        "      latent_size=100)"
      ],
      "metadata": {
        "id": "yxeXscY6LT_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_weights(m):\n",
        "  '''\n",
        "    Try resetting model weights to avoid\n",
        "    weight leakage.\n",
        "  '''\n",
        "  for layer in m.children():\n",
        "   if hasattr(layer, 'reset_parameters'):\n",
        "    print(f'Reset trainable parameters of layer = {layer}')\n",
        "    layer.reset_parameters()"
      ],
      "metadata": {
        "id": "VqlDltOcEigI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_VAE_model(net, dataset, k, epochs, batch_size, beta):\n",
        "  #https://github.com/christianversloot/machine-learning-articles/blob/main/\n",
        "  #how-to-use-k-fold-cross-validation-with-pytorch.md\n",
        "\n",
        "  if __name__ == '__main__':\n",
        "    \n",
        "    # Configuration options\n",
        "    k_folds = k\n",
        "    epochs = epochs\n",
        "    #loss_function = nn.CrossEntropyLoss()\n",
        "    loss_function = nn.MSELoss()\n",
        "    \n",
        "    # For fold results\n",
        "    train_results = {}\n",
        "    val_results = {}\n",
        "    \n",
        "    # Set fixed random number seed\n",
        "    torch.manual_seed(42)\n",
        "    \n",
        "    # Prepare dataset by concatenating Train/Test part; we split later.\n",
        "\n",
        "    dataset = dataset\n",
        "    \n",
        "    # Define the K-fold Cross Validator\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
        "      \n",
        "    # Start print\n",
        "    print('--------------------------------')\n",
        "\n",
        "    # K-fold Cross Validation model evaluation\n",
        "    for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
        "      \n",
        "      # Print\n",
        "      print(f'FOLD {fold}')\n",
        "      print('--------------------------------')\n",
        "      \n",
        "      # Sample elements randomly from a given list of ids, no replacement.\n",
        "      train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "      test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "      \n",
        "      # Define data loaders for training and testing data in this fold\n",
        "      trainloader = torch.utils.data.DataLoader(\n",
        "                        dataset, \n",
        "                        batch_size=batch_size, sampler=train_subsampler)\n",
        "      testloader = torch.utils.data.DataLoader(\n",
        "                        dataset,\n",
        "                        batch_size=batch_size, sampler=test_subsampler)\n",
        "      \n",
        "\n",
        "      net = net\n",
        "      net.apply(reset_weights)\n",
        "\n",
        "      # create an optimizer object\n",
        "      # Adam optimizer with learning rate 1e-3\n",
        "      optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "\n",
        "      # Run the training loop for defined number of epochs\n",
        "      for epoch in range(1, epochs + 1):\n",
        "          print(f'\\n Epoch {epoch}')\n",
        "          loss = 0\n",
        "          training_loss = 0\n",
        "          test_loss = 0\n",
        "          val_latents = []\n",
        "          val_outputs = []\n",
        "          train_outputs = []\n",
        "          for i, (batch_features) in enumerate(trainloader):\n",
        "              optimizer.zero_grad()\n",
        "              # Reshape data so each image is an array with 784 elements\n",
        "              batch_features = batch_features.view(-1, 204)\n",
        "\n",
        "              criterion, output, latent = net(batch_features, beta)\n",
        "              criterion.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "              #avg_loss += loss.item()/len(train_data)\n",
        "\n",
        "              #z, mu_e, logvar_e = net.encode(batch_features)\n",
        "              #output = net.decode(z)\n",
        "              \n",
        "              train_outputs.append(output.detach().numpy())\n",
        "              \n",
        "              train_loss = loss_function(output, batch_features)\n",
        "              \n",
        "              # Print statistics\n",
        "              loss += train_loss.item()\n",
        "              training_loss += train_loss.item()\n",
        "              \n",
        "              \n",
        "\n",
        "              if i % 100 == 0:\n",
        "                  # Print average loss per sample in batch\n",
        "                  batch_loss = loss/len(batch_features)\n",
        "                  print(f'\\r[{i:d}/{len(batch_features):d}] batch loss: {batch_loss} ',\n",
        "                        end='', flush=True)\n",
        "              loss = 0\n",
        "            \n",
        "\n",
        "      # Process is complete.\n",
        "      print('Training process has finished. Saving trained model.')\n",
        "\n",
        "      # Print about testing\n",
        "      #print('Starting testing')\n",
        "\n",
        "      # Evaluation for this fold\n",
        "\n",
        "      with torch.no_grad():\n",
        "\n",
        "        # Iterate over the test data and generate predictions\n",
        "        for i, (batch_features) in enumerate(testloader):\n",
        "\n",
        "            # Reshape data so each image is an array with 784 elements\n",
        "            batch_features = batch_features.view(-1, 204)\n",
        "\n",
        "            #test_loss = net(batch_features)\n",
        "            criterion, output, latent = net(batch_features, beta)\n",
        "            \n",
        "            val_outputs.append(output.detach().numpy())\n",
        "            val_latents.append(latent.detach().numpy())\n",
        "            val_loss = loss_function(output, batch_features)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            test_loss += val_loss.item()\n",
        "\n",
        "\n",
        "        train_outputs = np.concatenate( train_outputs, axis=0 )\n",
        "        val_outputs = np.concatenate( val_outputs, axis=0 )\n",
        "        val_latents = np.concatenate( val_latents, axis=0 )\n",
        "        model_train_loss = training_loss / len(train_outputs\n",
        "                          )\n",
        "        test_loss = test_loss / len(val_outputs\n",
        "                          )\n",
        "        #animator.add(epoch, (loss, test_loss))\n",
        "        #print(train_iter[0][:5])\n",
        "        #print(outputs[:5])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Print fold loss\n",
        "        print(f'Training loss for fold {fold}: {model_train_loss}')\n",
        "        print(f'Validation loss for fold {fold}: {test_loss}')\n",
        "        print('--------------------------------')\n",
        "        train_results[fold] = model_train_loss\n",
        "        val_results[fold] = test_loss\n",
        "    # Print fold results\n",
        "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
        "    print('--------------------------------')\n",
        "    train_sum = 0.0\n",
        "    val_sum = 0.0\n",
        "    for key, value in train_results.items():\n",
        "      print(f'Training Fold {key} Loss: {value}')\n",
        "      train_sum += value\n",
        "    print(f'Trainig Average Loss: {train_sum/len(train_results.items())}')\n",
        "    train_avg_loss = train_sum/len(train_results.items())\n",
        "    for key, value in val_results.items():\n",
        "      print(f'Validation Fold {key} Loss: {value} ')\n",
        "      val_sum += value\n",
        "    print(f'Vaidation Average Loss: {val_sum/len(val_results.items())}')\n",
        "    val_avg_loss = val_sum/len(val_results.items())\n",
        "\n",
        "    full_outputs = []\n",
        "    full_outputs.append(train_avg_loss)\n",
        "    full_outputs.append(val_avg_loss)\n",
        "    full_outputs.append(val_latents)\n",
        "    full_outputs.append(val_outputs)\n",
        "    full_outputs.append(train_outputs)\n",
        "\n",
        "    \n",
        "\n",
        "    return full_outputs\n",
        "\n",
        "        \n"
      ],
      "metadata": {
        "id": "Nf_rJV1fES9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "k = 5\n",
        "latent_size = [4, 15, 25, 50,100]\n"
      ],
      "metadata": {
        "id": "PoGod731PqmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_4_1 = train_VAE_model(net=net1_4,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.2)\n"
      ],
      "metadata": {
        "id": "M2ArtXE_EZQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c668a3c-ea7a-4aef-e43c-d507277f7f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.000394474423956126 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003491778043098748 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003564002690836787 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003143769863527268 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00031732572824694216 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0002901579427998513 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003220595244783908 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00030565966153517365 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00030178535962477326 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003243250248488039 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00029800174525007606 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003101502952631563 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003247162385378033 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003015993279404938 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0003127056988887489 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.000310511386487633 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00032006774563342333 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003251807065680623 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00033166620414704084 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00032023843959905207 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0003099803871009499 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003072949475608766 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00028583803214132786 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003249509318266064 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00033368353615514934 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00033592115505598485 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00030015932861715555 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003085027856286615 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.000326815847074613 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.000311459181830287 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.00031176907549033294\n",
            "Validation loss for fold 0: 0.00032049404608634833\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.000358237826731056 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003568188985809684 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00032241115695796907 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003104867646470666 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00035737184225581586 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003544490609783679 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00033475918462499976 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00033337846980430186 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003202491789124906 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003311597974970937 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00033965916372835636 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00032317565637640655 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003164087247569114 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003396431275177747 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0002918183454312384 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00033950628130696714 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003196562174707651 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003021386219188571 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002974072704091668 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0003257076896261424 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00028576719341799617 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.000307994254399091 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003052462707273662 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003504521446302533 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00031484776991419494 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003099320747423917 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00031990930438041687 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00030132720712572336 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003137999156024307 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0003114574356004596 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.00031375430990370086\n",
            "Validation loss for fold 1: 0.00031784816486528546\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00039242624188773334 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00033017544774338603 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003515671123750508 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003550235996954143 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003574792353902012 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00035219950950704515 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003442928718868643 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00034952678834088147 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003381138958502561 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003146008530166 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00035493995528668165 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003130657132714987 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003578025789465755 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003573311259970069 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00030850115581415594 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003372942446731031 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003548614331521094 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00032779492903500795 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003538616292644292 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0003291857137810439 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00036192144034430385 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003258239303249866 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00034706154838204384 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003138419706374407 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0003181201172992587 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00030857353704050183 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.000320502178510651 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003459888102952391 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003224835090804845 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00032916440977714956 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.00033135440416317646\n",
            "Validation loss for fold 2: 0.00033794666661402016\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003741669934242964 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003396918473299593 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00035057892091572285 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00034263762063346803 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00034825390321202576 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00032504391856491566 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00035146347363479435 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00032706011552363634 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00034422861062921584 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.000332088879076764 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00033282864023931324 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.000337613164447248 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00033262729994021356 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00031248360755853355 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0003193712327629328 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00031730043701827526 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002967200707644224 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002982875157613307 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00032277157879434526 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0003399867273401469 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00032974101486615837 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003065826022066176 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003139862383250147 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00031573206069879234 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002983470039907843 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003459863073658198 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0003047515347134322 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002972660877276212 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00031728140311315656 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.000318869948387146 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.00031192449851385876\n",
            "Validation loss for fold 3: 0.00031784185203087307\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003533351991791278 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00035677902633324265 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00033289045677520335 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00034675479400902987 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003469156799837947 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003142294299323112 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00030824975692667067 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00032309183734469116 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00034506063093431294 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003497709985822439 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00033789928420446813 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003112122940365225 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00030553966644220054 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003034580731764436 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00032675484544597566 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003301914839539677 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003285220009274781 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00032980958349071443 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00031287758611142635 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00029508405714295805 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0003184516099281609 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00029013596940785646 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003186661924701184 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00031321123242378235 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0003189454728271812 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00032832613214850426 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0003028159844689071 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003197687619831413 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00030371741740964353 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00031614716863259673 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.0003047617097563116\n",
            "Validation loss for fold 4: 0.0003106703220634279\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.00031176907549033294\n",
            "Training Fold 1 Loss: 0.00031375430990370086\n",
            "Training Fold 2 Loss: 0.00033135440416317646\n",
            "Training Fold 3 Loss: 0.00031192449851385876\n",
            "Training Fold 4 Loss: 0.0003047617097563116\n",
            "Trainig Average Loss: 0.00031471279956547614\n",
            "Validation Fold 0 Loss: 0.00032049404608634833 \n",
            "Validation Fold 1 Loss: 0.00031784816486528546 \n",
            "Validation Fold 2 Loss: 0.00033794666661402016 \n",
            "Validation Fold 3 Loss: 0.00031784185203087307 \n",
            "Validation Fold 4 Loss: 0.0003106703220634279 \n",
            "Vaidation Average Loss: 0.000320960210331991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_15_1 = train_VAE_model(net=net1_15,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.2)"
      ],
      "metadata": {
        "id": "Xgf4ywkrQiE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971a14a0-edf4-4c07-a883-396279a846d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003559561155270785 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003615606692619622 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.000321152969263494 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003245329426135868 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00033937045373022556 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003315802023280412 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00028595104231499135 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003053889668080956 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003024670295417309 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00030854003853164613 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0002943808794952929 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003011789813172072 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002979307319037616 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00027940591098740697 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00028520182240754366 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00027689203852787614 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00027935425168834627 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00026415722095407546 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002596089616417885 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00028148837736807764 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00026355087175033987 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.000259490218013525 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00025801040465012193 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002883122942876071 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002607729402370751 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00024544738698750734 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.000275364494882524 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00026855056057684124 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002601910673547536 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00027685824898071587 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.00026328189860899936\n",
            "Validation loss for fold 0: 0.00027402532030350784\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003897624555975199 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003549936518538743 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003517674340400845 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.000317571684718132 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003282683319412172 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00033491081558167934 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.000296049372991547 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0002964299055747688 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003088449302595109 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002889435854740441 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00028482117340900004 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002886044676415622 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002791841689031571 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0002791715960483998 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.000262020475929603 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00029500992968678474 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00026385748060420156 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002727839455474168 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00025612112949602306 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00026730631361715496 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00025986842229031026 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00022830182570032775 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00027542453608475626 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.000256257044384256 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002496109518688172 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002600418229121715 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002532026846893132 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00026144602452404797 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00022805394837632775 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00023179267009254545 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.00024817106904440403\n",
            "Validation loss for fold 1: 0.0002545156387954192\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003593038709368557 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003719358646776527 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003872342058457434 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00033921192516572773 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003134492435492575 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003173177829012275 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0002880540559999645 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00030313467141240835 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003126480442006141 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003285162092652172 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003132650745101273 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002818181528709829 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00026074654306285083 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00027484173187986016 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0002920459082815796 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002878062368836254 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002843230322469026 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002511448401492089 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00028638436924666166 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002458598173689097 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00025600878871046007 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002708708925638348 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00027914802194572985 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00027707702247425914 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002570058568380773 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002652486728038639 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00026596288080327213 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002823134127538651 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00025990884751081467 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002594808174762875 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.00026444849141776333\n",
            "Validation loss for fold 2: 0.0002708103494409841\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.000426901679020375 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003195597091689706 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00038791901897639036 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003417967236600816 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003052176325581968 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0002986167964991182 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003062646428588778 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00029051280580461025 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0002804796677082777 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00030163387418724597 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0002928852045442909 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00025743452715687454 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00028310102061368525 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0002781549410428852 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0002827639982569963 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00027831108309328556 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00027914930251426995 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002778461785055697 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00027867223252542317 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00028124681557528675 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00025045775691978633 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002659156161826104 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00026473187608644366 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002553659141995013 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002696304873097688 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00024124961055349559 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002504480944480747 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002579817082732916 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00026044598780572414 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002679066965356469 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.0002539300767266152\n",
            "Validation loss for fold 3: 0.0002581576890608308\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0004027872928418219 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00034680255339480937 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00035972901969216764 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003434653044678271 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.000330562237650156 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00030798849184066057 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0002877685765270144 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.000297079561278224 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0002515706582926214 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00028978215414099395 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0002790660655591637 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00029560428811237216 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002918196842074394 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0002836200874298811 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00024336636124644428 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00026522830012254417 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002640877210069448 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.000247260119067505 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002631197858136147 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002520836133044213 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00023596416576765478 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00024625606602057815 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00025789879146032035 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002522853319533169 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002447834121994674 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00023952762421686202 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002488319587428123 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002607038477435708 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00024811149341985583 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002381336671533063 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.0002438796477952444\n",
            "Validation loss for fold 4: 0.0002492564416990047\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.00026328189860899936\n",
            "Training Fold 1 Loss: 0.00024817106904440403\n",
            "Training Fold 2 Loss: 0.00026444849141776333\n",
            "Training Fold 3 Loss: 0.0002539300767266152\n",
            "Training Fold 4 Loss: 0.0002438796477952444\n",
            "Trainig Average Loss: 0.00025474223671860524\n",
            "Validation Fold 0 Loss: 0.00027402532030350784 \n",
            "Validation Fold 1 Loss: 0.0002545156387954192 \n",
            "Validation Fold 2 Loss: 0.0002708103494409841 \n",
            "Validation Fold 3 Loss: 0.0002581576890608308 \n",
            "Validation Fold 4 Loss: 0.0002492564416990047 \n",
            "Vaidation Average Loss: 0.0002613530878599493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_25_1 = train_VAE_model(net=net1_25,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.2)"
      ],
      "metadata": {
        "id": "lKtYv-uN_9DJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f0fd45-3d94-492f-db72-9bed75b81f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003574177098926157 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00036951739457435906 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003575880255084485 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003362455463502556 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.000306662026559934 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003114981227554381 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003145553928334266 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00029035337502136827 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0002840416564140469 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002739263291005045 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00027132127434015274 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00026292551774531603 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00023292585683520883 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0002483725256752223 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0002629209775477648 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002576728293206543 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00022636225912719965 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002500656119082123 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002465818834025413 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00025830394588410854 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00025965593522414565 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00023855009931139648 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00024942198069766164 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00022192463802639395 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00022870207612868398 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00023280407185666263 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00023769222025293857 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00022663621348328888 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002349643036723137 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002533170045353472 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.0002328725992827802\n",
            "Validation loss for fold 0: 0.00024070905570759135\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003587638202589005 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003635442117229104 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00032113687484525144 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00033072306541725993 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003141300694551319 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003006023180205375 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.000297349615721032 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.000286988535663113 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003074032429140061 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003117414307780564 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00027425415464676917 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00025153745082207024 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002696813317015767 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00026648640050552785 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0002790186263155192 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002814628242049366 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002528935729060322 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002618646831251681 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00026773393619805574 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00024359099916182458 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00027828646125271916 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00028117885813117027 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002435932692606002 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00027695350581780076 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002380516816629097 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00023235181288328022 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00023557257372885942 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002454238128848374 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00023419919307343662 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002440578246023506 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.00023856459828417275\n",
            "Validation loss for fold 1: 0.0002446695103641201\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00038270442746579647 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00035027312696911395 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003042898897547275 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003159319458063692 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.000319873885018751 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00031949992990121245 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0002984104794450104 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003094218554906547 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0002756334433797747 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002668342785909772 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0002520275884307921 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002858811931218952 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00024077750276774168 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00027275484171696007 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0002505033917259425 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002434927155263722 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00024031968496274203 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00027390438481234014 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002517598622944206 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00023987905296962708 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00024003810540307313 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00023051070456858724 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00022222437837626785 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00022572054876945913 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002481904230080545 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.000252657599048689 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002316766622243449 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00025363414897583425 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002395320771029219 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.000228790013352409 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.00023063189930437155\n",
            "Validation loss for fold 2: 0.0002381885470281656\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00037250580498948693 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003500554885249585 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.000321051076753065 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003014611720573157 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003176162426825613 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003109606041107327 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00031293759820982814 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.000265749724349007 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003055421984754503 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002850903256330639 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00028200753149576485 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002827280550263822 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002663514460437 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00026940007228404284 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00026549710310064256 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00027139997109770775 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002780466165859252 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002759501221589744 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00027599031454883516 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00024809082970023155 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002479678951203823 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002854138729162514 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00022635112691204995 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00023193564265966415 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002343570376979187 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00022872693079989403 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00023809117556083947 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00026135172811336815 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002370033907936886 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002568027121014893 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.0002428964237218658\n",
            "Validation loss for fold 3: 0.00024862584966566935\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003972762788180262 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00034990557469427586 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003376948006916791 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00032822368666529655 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0002990464272443205 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00029717356665059924 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0002944174921140075 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003023955214302987 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0002757854526862502 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002633789263200015 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00026373236323706806 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00026568619068711996 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00028000836027786136 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00026806368259713054 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0002684243372641504 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00026498333318158984 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00025297366664744914 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00024014546943362802 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00025371109950356185 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00024653016589581966 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002226300275651738 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00026474572950974107 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00025326022296212614 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00026978194364346564 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00024193826538976282 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002578323183115572 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002531598729547113 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00025952383293770254 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002499939000699669 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002306652459083125 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.00023647566105731334\n",
            "Validation loss for fold 4: 0.00024250945511109363\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.0002328725992827802\n",
            "Training Fold 1 Loss: 0.00023856459828417275\n",
            "Training Fold 2 Loss: 0.00023063189930437155\n",
            "Training Fold 3 Loss: 0.0002428964237218658\n",
            "Training Fold 4 Loss: 0.00023647566105731334\n",
            "Trainig Average Loss: 0.0002362882363301007\n",
            "Validation Fold 0 Loss: 0.00024070905570759135 \n",
            "Validation Fold 1 Loss: 0.0002446695103641201 \n",
            "Validation Fold 2 Loss: 0.0002381885470281656 \n",
            "Validation Fold 3 Loss: 0.00024862584966566935 \n",
            "Validation Fold 4 Loss: 0.00024250945511109363 \n",
            "Vaidation Average Loss: 0.000242940483575328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_50_1 = train_VAE_model(net=net1_50,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.2)"
      ],
      "metadata": {
        "id": "EkYXO8e__-pS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf10180-bccf-46ff-d282-704461138f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00038333082920871675 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003683881077449769 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00033496966352686286 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00034547410905361176 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003277776704635471 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003241014201194048 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003175133606418967 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00029242949676699936 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00028394817491061985 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002912175841629505 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00025644234847277403 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00027223918004892766 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00025414692936465144 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00025481474585831165 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00027141885948367417 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00027716808835975826 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00026573598734103143 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002348116977373138 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00026048050494864583 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00025069128605537117 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00026431240257807076 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002602744789328426 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002630462986417115 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002437413641018793 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00022863286721985787 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00026253258693031967 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002417784562567249 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002241368783870712 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00022654340136796236 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00022345622710417956 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.0002311615376628964\n",
            "Validation loss for fold 0: 0.00023810000211545382\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00038654168020002544 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003643424133770168 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00033665471710264683 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003443762834649533 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00030688164406456053 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00030403610435314476 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00031437879079021513 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00029366867966018617 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0002652070252224803 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002855595957953483 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0002769534767139703 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002599486615508795 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002773944288492203 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00027046765899285674 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00027343863621354103 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00025736188399605453 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002522174618206918 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00024826277513056993 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00025376476696692407 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00025486707454547286 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00024301334633491933 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00024148935335688293 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00023744854843243957 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00022678964887745678 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002452717162668705 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002622195752337575 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00020851439330726862 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002476078807376325 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00020214759570080787 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00022983520466368645 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.0002296751915372937\n",
            "Validation loss for fold 1: 0.00023561303209479367\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003564126091077924 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0004040102649014443 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00034044121275655925 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003490196249913424 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00031037587905302644 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.000297027756460011 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00029421085491776466 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00030427309684455395 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00029308992088772357 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00029146953602321446 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0002918013196904212 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002653607807587832 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002876141807064414 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00027643321664072573 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00022397302382159978 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00028904795181006193 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002630590461194515 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00023265481286216527 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002553901867941022 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002736422175075859 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00025519923656247556 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002362222585361451 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00023784766381140798 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002476507506798953 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002290445554535836 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.000197715125977993 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002773427404463291 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00021880201529711485 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00024257875338662416 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00023285276256501675 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.00023616304924589326\n",
            "Validation loss for fold 2: 0.00024347838607170506\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003693728649523109 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003641706716734916 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00032653255038894713 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00030657602474093437 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003359031106811017 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00029095803620293736 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00030696208705194294 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0002831636229529977 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00029143603751435876 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002791044535115361 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00026226663612760603 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002704840444494039 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00026490684831514955 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00027684931410476565 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00026315427385270596 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002628337242640555 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002642104809638113 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00027084388420917094 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002503264113329351 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00021699271746911108 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002426382852718234 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002487115853000432 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00025815542903728783 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00023613026132807136 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002550872159190476 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00021532867685891688 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00024279605713672936 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00022304810408968478 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002283387293573469 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00022358051501214504 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.00023132637586142566\n",
            "Validation loss for fold 3: 0.00023889159086437205\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0004034912562929094 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003314251371193677 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00032681875745765865 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003172473516315222 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003129218239337206 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0002998030395247042 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003076336288359016 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0002876805665437132 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0002860682434402406 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00027051320648752153 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0002848900912795216 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002910479379352182 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002545673924032599 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00024983834009617567 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0002623201289679855 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.000286230118945241 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00025823013857007027 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002398110373178497 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002498746325727552 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002530351630412042 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002649809466674924 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00024650932755321264 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002490812330506742 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00024087776546366513 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00025086847017519176 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00024032765941228718 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00024110364029183984 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002471210900694132 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00023827259428799152 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00023815289023332298 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.00023111402439581765\n",
            "Validation loss for fold 4: 0.00023561087618221183\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.0002311615376628964\n",
            "Training Fold 1 Loss: 0.0002296751915372937\n",
            "Training Fold 2 Loss: 0.00023616304924589326\n",
            "Training Fold 3 Loss: 0.00023132637586142566\n",
            "Training Fold 4 Loss: 0.00023111402439581765\n",
            "Trainig Average Loss: 0.00023188803574066534\n",
            "Validation Fold 0 Loss: 0.00023810000211545382 \n",
            "Validation Fold 1 Loss: 0.00023561303209479367 \n",
            "Validation Fold 2 Loss: 0.00024347838607170506 \n",
            "Validation Fold 3 Loss: 0.00023889159086437205 \n",
            "Validation Fold 4 Loss: 0.00023561087618221183 \n",
            "Vaidation Average Loss: 0.00023833877746570726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_100_1 = train_VAE_model(net=net1_100,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.2)"
      ],
      "metadata": {
        "id": "zOUd4TUz4Ae0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafaf250-ea30-4da9-d473-8891b13bd5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00037805704050697386 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003454225661698729 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003188308619428426 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00035555247450247407 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003156704769935459 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00028139271307736635 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00030219185282476246 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00028679947718046606 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0002951936039607972 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00028273623320274055 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0002633985423017293 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00029163810540921986 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002763486991170794 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00027618397143669426 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00026497148792259395 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00028153363382443786 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002561452565714717 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002676275616977364 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002450799220241606 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00024086945632006973 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002233088598586619 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00024536909768357873 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00024762473185546696 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00023439388314727694 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00023517136287409812 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00024227259564213455 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002439592790324241 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00025807932252064347 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00022567548148799688 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00026053714100271463 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.00023601393591483126\n",
            "Validation loss for fold 0: 0.00024225566262797658\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0004106003325432539 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003684691619127989 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.000358489400241524 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00033339261426590383 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00031688870512880385 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003100399917457253 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00030694084125570953 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0002791953447740525 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0002742420765571296 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002687392116058618 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00028737258980982006 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00027626004884950817 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00025194312911480665 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00024892843794077635 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0002605410118121654 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002474512148182839 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.000248788739554584 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00024979677982628345 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00024475387181155384 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002626838395372033 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00027381585096009076 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00021312086028046906 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00024349552404601127 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00022701302077621222 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00023421659716404974 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00023108576715458184 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00023224808683153242 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00026339295436628163 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00025216746143996716 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00022570851433556527 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.0002350330601327668\n",
            "Validation loss for fold 1: 0.00024247419826404706\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00039448600728064775 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00037948961835354567 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003362470888532698 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003471412928774953 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00032386890961788595 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003051977255381644 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0002822249662131071 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0002836610656231642 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0002815536572597921 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00026583002181723714 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0002587506896816194 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002741675707511604 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002832879254128784 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0002768833073787391 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00026318791788071394 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00026779487961903214 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.000266013405052945 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00025263766292482615 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00025916247977875173 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002397194184595719 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002446490107104182 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00024261126236524433 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00023773396969772875 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00025887429364956915 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00026148042525164783 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00023512178449891508 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002437734219711274 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002155909751309082 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00023428573331329972 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00023329946270678192 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.00022838366860128276\n",
            "Validation loss for fold 2: 0.00023399863607513187\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003710334131028503 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00035236089024692774 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.000355048687197268 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003353847423568368 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00032594622462056577 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003216375189367682 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0002859206579159945 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00027733464958146214 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003006423939950764 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002696012379601598 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00026964175049215555 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002787554112728685 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002506835444364697 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0002578033017925918 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00026575717492960393 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.000260404369328171 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.000273877230938524 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00024113983090501279 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002441546239424497 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00025547409313730896 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00025151725276373327 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00022197312500793487 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00023774542205501348 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00024208259128499776 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00021814237697981298 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00026770049589686096 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00022067149984650314 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002333245356567204 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00022375202388502657 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00024301106168422848 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.00022861930394264723\n",
            "Validation loss for fold 3: 0.00023316653721054779\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00037012764369137585 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003962160262744874 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00036495583481155336 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003417824627831578 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003078002482652664 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00031560033676214516 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00030438569956459105 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.000299695908324793 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00028591020964086056 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00027368348673917353 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00026286160573363304 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00029896851629018784 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00028350771754048765 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0002821036905515939 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00026817992329597473 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00026218174025416374 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002456262009218335 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002472689375281334 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00024404704163316637 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00026044779224321246 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002609295479487628 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00028138377820141613 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002465714933350682 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002424728882033378 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00026208293274976313 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00023726382642053068 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00021497491979971528 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002325531531823799 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00023425593099091202 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00022623933909926564 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.0002343610253218172\n",
            "Validation loss for fold 4: 0.00024314174270005334\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.00023601393591483126\n",
            "Training Fold 1 Loss: 0.0002350330601327668\n",
            "Training Fold 2 Loss: 0.00022838366860128276\n",
            "Training Fold 3 Loss: 0.00022861930394264723\n",
            "Training Fold 4 Loss: 0.0002343610253218172\n",
            "Trainig Average Loss: 0.00023248219878266906\n",
            "Validation Fold 0 Loss: 0.00024225566262797658 \n",
            "Validation Fold 1 Loss: 0.00024247419826404706 \n",
            "Validation Fold 2 Loss: 0.00023399863607513187 \n",
            "Validation Fold 3 Loss: 0.00023316653721054779 \n",
            "Validation Fold 4 Loss: 0.00024314174270005334 \n",
            "Vaidation Average Loss: 0.00023900735537555132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "emH1oYUNL4q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_4_2 = train_VAE_model(net=net2_4,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuvKWF5jMNU-",
        "outputId": "c56039ab-e2d3-4f2d-d0be-c231228f9194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003925507189705968 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003442215675022453 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00034432485699653625 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003351193736307323 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003387601755093783 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003088455705437809 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003428835771046579 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00031881267204880714 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003210875147487968 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00033601370523683727 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003213156305719167 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002974401577375829 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00033673568395897746 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003293338813818991 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00034203584073111415 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003409167402423918 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00032428649137727916 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003417121188249439 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00029121534316800535 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002894817152991891 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00033197319135069847 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00033307087142020464 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.000342408602591604 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003148865944240242 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0003093093109782785 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00034173863241449 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00032701902091503143 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00032274663681164384 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003295640926808119 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00035122150438837707 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.0003217858546719128\n",
            "Validation loss for fold 0: 0.0003274320052903995\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003770285111386329 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00035993001074530184 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00032297841971740127 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003403797745704651 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003267830761615187 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00036620019818656147 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003338027745485306 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00034839846193790436 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003726805152837187 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003373214858584106 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.000350768503267318 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.000370293011656031 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00034810672514140606 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003454201214481145 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00037498827441595495 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003388620389159769 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003427590418141335 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00035082007525488734 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003423051384743303 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0003208050038665533 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00034453117405064404 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00034849593066610396 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003682450915221125 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00034069694811478257 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00035062263486906886 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003597135655581951 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00032454877509735525 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00032002749503590167 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003212493029423058 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00035058706998825073 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.00033759459968239183\n",
            "Validation loss for fold 1: 0.0003449084807471755\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003631660365499556 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003804835141636431 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003761571424547583 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00039443784044124186 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00038009262061677873 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.000337126140948385 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003430576471146196 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00033968352363444865 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003628445556387305 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00036048886249773204 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.000347418274031952 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00034034185227937996 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003373075742274523 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003554389695636928 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0003322742704767734 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003544118080753833 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003188057744409889 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.000327211688272655 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.000358411343768239 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00034801792935468256 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00034759234404191375 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00038209371268749237 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00032160934642888606 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003444415924604982 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0003291939792688936 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00033011133200488985 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00034909090027213097 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00032869342248886824 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00034325828892178833 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00033157350844703615 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.00033790432129587444\n",
            "Validation loss for fold 2: 0.00034191079478234986\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003791755298152566 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00033697643084451556 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00035139694227837026 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00036550647928379476 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003309544699732214 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00035066920099779963 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00034615793265402317 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003662537783384323 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003323356795590371 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002869682211894542 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00034696608781814575 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003675553889479488 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00033506445470266044 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003265276609454304 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00032675193506293 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00034405163023620844 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00034187492565251887 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003322112315800041 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00033625756623223424 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0003448053903412074 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00033814276685006917 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00034919916652143 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003128309908788651 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003204409731552005 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0003351164632476866 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00032873504096642137 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00033943195012398064 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00032192555954679847 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00031838755239732563 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0003030123480129987 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.00032339536073585273\n",
            "Validation loss for fold 3: 0.000329124228303922\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00034696137299761176 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00039201733306981623 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003629126586019993 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00040104324580170214 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003688783326651901 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003505120403133333 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003796425589825958 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003449539071880281 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003364244184922427 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00034738221438601613 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003522174956742674 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00033043380244635046 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00034407380735501647 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003428311028983444 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00034125178353860974 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00032011521398089826 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00034466618672013283 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00033322774106636643 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003414747479837388 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00035404108348302543 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00034342281287536025 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003269053704570979 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00033448406611569226 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003358184185344726 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00035309657687321305 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003386008320376277 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00032897506025619805 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00036115467082709074 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00034552652505226433 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00034441653406247497 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.0003384140240498419\n",
            "Validation loss for fold 4: 0.00034078133490314505\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.0003217858546719128\n",
            "Training Fold 1 Loss: 0.00033759459968239183\n",
            "Training Fold 2 Loss: 0.00033790432129587444\n",
            "Training Fold 3 Loss: 0.00032339536073585273\n",
            "Training Fold 4 Loss: 0.0003384140240498419\n",
            "Trainig Average Loss: 0.0003318188320871747\n",
            "Validation Fold 0 Loss: 0.0003274320052903995 \n",
            "Validation Fold 1 Loss: 0.0003449084807471755 \n",
            "Validation Fold 2 Loss: 0.00034191079478234986 \n",
            "Validation Fold 3 Loss: 0.000329124228303922 \n",
            "Validation Fold 4 Loss: 0.00034078133490314505 \n",
            "Vaidation Average Loss: 0.0003368313688053984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_15_2 = train_VAE_model(net=net2_15,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQvIl9RxMNVK",
        "outputId": "9e8fe44a-b217-4e02-d8ea-5b08ca5d97eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00034855148987844586 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003756382211577147 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003944325726479292 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003616010071709752 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00035290472442284226 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00034155501634813845 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003245070402044803 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00032139092218130827 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003044879122171551 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003220988146495074 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00030390062602236867 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00030699349008500576 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002998737327288836 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003244797117076814 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00033751921728253365 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00029913976322859526 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003089233359787613 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00030425519798882306 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002862995897885412 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002971955109387636 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0003062257601413876 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003015908587258309 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003218956117052585 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00027428127941675484 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002898185630328953 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002987854240927845 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002655547868926078 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002926246961578727 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002949984045699239 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00029711329261772335 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.00029278130938647796\n",
            "Validation loss for fold 0: 0.000298335661314021\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00042680196929723024 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0004119498189538717 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003438772982917726 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003643154923338443 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00034698573290370405 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003067865327466279 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00032154881046153605 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00033216149313375354 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003490918898023665 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003258608339820057 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00032292440300807357 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002872568729799241 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00032454743632115424 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0002796479093376547 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0002994097303599119 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00031556960311718285 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002843898255378008 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003008368657901883 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002975763054564595 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002917769306804985 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0003136492450721562 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002575812104623765 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00025613486650399864 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00028147539705969393 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002809506841003895 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002824620751198381 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00027373182820156217 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00029329248354770243 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00026570737827569246 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00026547687593847513 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.0002849106299601006\n",
            "Validation loss for fold 1: 0.000290777241525339\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00036018958780914545 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003770367184188217 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003492041432764381 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003492723626550287 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00036821028334088624 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00037045215140096843 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00035291750100441277 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003274211776442826 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003138883621431887 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003081944596488029 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003303287085145712 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003176808822900057 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003257577773183584 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.000305673573166132 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00030404626158997416 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002862071560230106 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002984638267662376 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003091046237386763 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003229118010494858 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002919118560384959 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00028264374122954905 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00030620285542681813 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002804629330057651 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002995296090375632 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002875008503906429 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002681320474948734 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002700072363950312 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00029774365248158574 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00028657037182711065 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.000288392388029024 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.00029197460113805233\n",
            "Validation loss for fold 2: 0.0002956843771793414\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00037695319042541087 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00036099134013056755 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003583507495932281 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003241474914830178 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003318869858048856 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003580663469620049 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00033485397580079734 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003440227301325649 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00031774144736118615 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003207729896530509 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00031122175278142095 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00032610964262858033 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003190306597389281 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0002810049045365304 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00027213036082684994 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003145377559121698 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00031194434268400073 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002966618339996785 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002842819958459586 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.000296270998660475 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00028530220151878893 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003028404898941517 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00030791631434112787 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00028317037504166365 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00029135707882232964 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003078456502407789 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002939834084827453 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002770452992990613 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002648008521646261 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00028868168010376394 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.00028571943173537383\n",
            "Validation loss for fold 3: 0.00028880864652419105\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00038359337486326694 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00034714327193796635 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003783539868891239 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00033950243960134685 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003339576651342213 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.000302643864415586 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00033472763607278466 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003185120294801891 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003352633793838322 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003320929827168584 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003024046018254012 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00030285658431239426 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00030544173205271363 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00030061090365052223 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00032795907463878393 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00029900416848249733 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.000325141882058233 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00029511807952076197 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003048058715648949 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.000297505030175671 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002806663978844881 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.000304656132357195 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003144881047774106 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00029469694709405303 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002818313369061798 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00028487032977864146 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00029571677441708744 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002976633550133556 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.000283392466371879 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00029850410646758974 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.00029177349985883005\n",
            "Validation loss for fold 4: 0.0003004170448806868\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.00029278130938647796\n",
            "Training Fold 1 Loss: 0.0002849106299601006\n",
            "Training Fold 2 Loss: 0.00029197460113805233\n",
            "Training Fold 3 Loss: 0.00028571943173537383\n",
            "Training Fold 4 Loss: 0.00029177349985883005\n",
            "Trainig Average Loss: 0.00028943189441576697\n",
            "Validation Fold 0 Loss: 0.000298335661314021 \n",
            "Validation Fold 1 Loss: 0.000290777241525339 \n",
            "Validation Fold 2 Loss: 0.0002956843771793414 \n",
            "Validation Fold 3 Loss: 0.00028880864652419105 \n",
            "Validation Fold 4 Loss: 0.0003004170448806868 \n",
            "Vaidation Average Loss: 0.00029480459428471586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_25_2 = train_VAE_model(net=net2_25,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJShNpRaMNVL",
        "outputId": "d60d534f-18f7-4c02-f2dc-9735117f6410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00038885854883119464 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003421770525164902 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003799800470005721 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003477782884147018 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00033360093948431313 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00035183251020498574 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003165138768963516 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003331753541715443 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00029839869239367545 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002966820902656764 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003313846536912024 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002771237341221422 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00028395987465046346 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00028616716735996306 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00029124011052772403 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002764603414107114 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002656677388586104 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00028109547565691173 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00029100209940224886 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002873107441700995 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002936332894023508 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00027440759004093707 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002965332823805511 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003051258099731058 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002596626291051507 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00028094524168409407 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002919255930464715 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003013496461790055 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00028780169668607414 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.000276893493719399 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.00028054915708004277\n",
            "Validation loss for fold 0: 0.0002837718892699853\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003979078319389373 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00037476205034181476 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003386165190022439 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003704633563756943 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00034850937663577497 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003557553864084184 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00030948882340453565 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003248940338380635 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.000301285763271153 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00029626034665852785 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.000280229898635298 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00031008085352368653 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00028073604335077107 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00031801633303985 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00030377888469956815 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00029654597165063024 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00031106805545277894 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00030423878342844546 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00027885325835086405 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.000292924145469442 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00028676193323917687 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00029322539921849966 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002896009827964008 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00029448774876073003 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002687537344172597 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002576930564828217 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002742889046203345 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.000266870716586709 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00031133685843087733 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00029243476456031203 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.00027835680947110457\n",
            "Validation loss for fold 1: 0.000283806000944123\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003754101344384253 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003516098950058222 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003537609882187098 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003444788744673133 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00035688671050593257 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003373966319486499 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003383925068192184 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003094174317084253 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003051805542781949 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003426735056564212 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003170253476127982 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002899262181017548 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002845899434760213 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.000293297809548676 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.000304656132357195 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00028331324574537575 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002948320470750332 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002975088427774608 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00029542914126068354 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002832770987879485 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002912332711275667 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00028092603315599263 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00029770898981951177 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002952575159724802 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0003186084213666618 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002921000123023987 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00027623213827610016 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002692455309443176 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003039122966583818 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00031600621878169477 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.00028386026977572203\n",
            "Validation loss for fold 2: 0.00028860779128893235\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003691292949952185 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003831287322100252 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00036764898686669767 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003464611654635519 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00036530307261273265 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003074243140872568 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003401069843675941 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00036676382296718657 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00032614043448120356 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002910676412284374 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00031486310763284564 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002999884891323745 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00028627293067984283 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00029575213557109237 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.000274805526714772 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003076210559811443 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002854843041859567 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00029214253299869597 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00029055512277409434 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002916564990300685 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002969093038700521 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002816102933138609 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00027557575958780944 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002789582940749824 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002814308973029256 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002937179815489799 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.000285418180283159 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00027595809660851955 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002808650897350162 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002985035243909806 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.0002829422911621889\n",
            "Validation loss for fold 3: 0.0002872259568948642\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.000377471384126693 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00037153519224375486 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003386604366824031 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003687485586851835 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003282040706835687 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00034221954410895705 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00032880614162422717 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00032909141737036407 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00031980627682060003 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0002857993822544813 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00028911035042256117 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003006071492563933 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00029720153543166816 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0002789994759950787 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00028159431531094015 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00027624028734862804 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002859895466826856 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00027775377384386957 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00028533407021313906 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00028607778949663043 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002786570694297552 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00029336949228309095 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002791497972793877 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00031591110746376216 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00029172058566473424 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002527197066228837 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002801541122607887 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00027510253130458295 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002851139288395643 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00028658242081291974 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.0002768064248102895\n",
            "Validation loss for fold 4: 0.0002838144944003732\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.00028054915708004277\n",
            "Training Fold 1 Loss: 0.00027835680947110457\n",
            "Training Fold 2 Loss: 0.00028386026977572203\n",
            "Training Fold 3 Loss: 0.0002829422911621889\n",
            "Training Fold 4 Loss: 0.0002768064248102895\n",
            "Trainig Average Loss: 0.0002805029904598696\n",
            "Validation Fold 0 Loss: 0.0002837718892699853 \n",
            "Validation Fold 1 Loss: 0.000283806000944123 \n",
            "Validation Fold 2 Loss: 0.00028860779128893235 \n",
            "Validation Fold 3 Loss: 0.0002872259568948642 \n",
            "Validation Fold 4 Loss: 0.0002838144944003732 \n",
            "Vaidation Average Loss: 0.0002854452265596556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_50_2 = train_VAE_model(net=net2_50,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poaIEyGLMNVM",
        "outputId": "639608d4-dbf9-4d10-8ade-a6a8c3a5c3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00042892646160908043 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00037453864933922887 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003484966291580349 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003429057833272964 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00034036635770462453 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003132734273094684 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003009892243426293 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003287487488705665 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00031239286181516945 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00029847610858269036 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00029100218671374023 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00031122349901124835 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002947998000308871 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0002818865468725562 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0002935405063908547 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00030537726706825197 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002724477672018111 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002898628590628505 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002676074218470603 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00031259909155778587 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002810528385452926 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00030109367799013853 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.000282247579889372 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00025509909028187394 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002733241708483547 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00030218149186111987 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00028557772748172283 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00028745440067723393 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002670983667485416 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002516580279916525 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.0002784679139673019\n",
            "Validation loss for fold 0: 0.00028424278547845125\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00039146319613792 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003621080832090229 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003474864352028817 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003576254821382463 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003627810801845044 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00034411021624691784 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00033110714866779745 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003142355417367071 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003203162632416934 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00032916537020355463 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00032268319046124816 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00031560950446873903 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002899734827224165 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0002901509578805417 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00028885476058349013 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002998698619194329 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00030390082974918187 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002729837142396718 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002678877499420196 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002842679969035089 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00026839537895284593 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002898220845963806 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00028991902945563197 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002850846212822944 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00027995239361189306 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00026102762785740197 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00029204064048826694 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003007316845469177 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002778751077130437 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00027230181149207056 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.0002777373464526357\n",
            "Validation loss for fold 1: 0.00028768317713644993\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00038310655509121716 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00038242797018028796 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003437490086071193 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00033929251367226243 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003856754337903112 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003380166308488697 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00033667395473457873 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00032368264510296285 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00033620453905314207 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00033264519879594445 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00031792992376722395 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00034154951572418213 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.000291813921649009 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0002995813556481153 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0003033786779269576 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002980906574521214 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002990609500557184 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00027593315462581813 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003218026249669492 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002900821273215115 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00029556683148257434 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002915147633757442 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002785328251775354 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00027709099231287837 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0003061364113818854 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00026559989782981575 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00028560610371641815 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002991733781527728 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00026821260689757764 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00028793353703804314 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.00028508588683190953\n",
            "Validation loss for fold 2: 0.00029195494506133467\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003685109841171652 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003957522567361593 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003673894389066845 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.000352381233824417 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003339411923661828 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003454339748714119 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00033635017462074757 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003233000752516091 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00031249955645762384 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00029796009766869247 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003268880245741457 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.000323501939419657 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00034727982711046934 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003238003992009908 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00029238511342555285 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002973887894768268 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002911062038037926 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00031504174694418907 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002784623939078301 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002877213410101831 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002736854657996446 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003029988147318363 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003154200967401266 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002667139342520386 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00027346351998858154 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00026723198243416846 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00029790253029204905 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.000273873854894191 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00027945320471189916 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00028977778856642544 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.00028071559442056194\n",
            "Validation loss for fold 3: 0.000282706718819139\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003922180039808154 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00037585111567750573 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003578046744223684 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003361656272318214 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00034979343763552606 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00032758538145571947 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003530230897013098 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003537796437740326 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003251105372328311 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00030615090508945286 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003111600235570222 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003194850869476795 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003029138024430722 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00030894094379618764 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00031647042487747967 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002835641207639128 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00029271378298290074 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0002999127609655261 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00030202465131878853 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002866108843591064 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00027723523089662194 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002793331223074347 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002897877129726112 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00029063792317174375 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00027017167303711176 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002765393874142319 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00028667744481936097 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00028258736710995436 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002807688433676958 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002504192234482616 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.00027946594604094264\n",
            "Validation loss for fold 4: 0.00028025979413453573\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.0002784679139673019\n",
            "Training Fold 1 Loss: 0.0002777373464526357\n",
            "Training Fold 2 Loss: 0.00028508588683190953\n",
            "Training Fold 3 Loss: 0.00028071559442056194\n",
            "Training Fold 4 Loss: 0.00027946594604094264\n",
            "Trainig Average Loss: 0.00028029453754267037\n",
            "Validation Fold 0 Loss: 0.00028424278547845125 \n",
            "Validation Fold 1 Loss: 0.00028768317713644993 \n",
            "Validation Fold 2 Loss: 0.00029195494506133467 \n",
            "Validation Fold 3 Loss: 0.000282706718819139 \n",
            "Validation Fold 4 Loss: 0.00028025979413453573 \n",
            "Vaidation Average Loss: 0.0002853694841259821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_100_2 = train_VAE_model(net=net2_100,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOK2_hwGMNVM",
        "outputId": "73be69de-1e1b-4a03-c60d-e7af5067d041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.000373863207641989 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003755995421670377 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00034580635838210583 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003210300928913057 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00038721851888112724 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.000341880222549662 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003630119317676872 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003456176200415939 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003212815208826214 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003400655114091933 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00031547044636681676 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.000315998651785776 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003087806107942015 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00030201557092368603 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0002907799498643726 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002730855194386095 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00027920803404413164 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00028191969613544643 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002794258180074394 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.000288482871837914 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00027753724134527147 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00028912388370372355 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00028779535205103457 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00028019555611535907 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00030464655719697475 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002729410771280527 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00028487390954978764 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002778539783321321 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00028994245803914964 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00032442581141367555 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.00028021843052508747\n",
            "Validation loss for fold 0: 0.00028437003079081043\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00040853419341146946 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00035406750976108015 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00034390046494081616 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00032766061485745013 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.000354068964952603 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.000359869038220495 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003143128997180611 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00034055273863486946 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003189704439137131 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00033570523373782635 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00033492050715722144 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00031596721964888275 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003113978891633451 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00030179237364791334 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0003254259063396603 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00032226915936917067 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00030134449480101466 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003244562540203333 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00027326217968948185 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00029592178179882467 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00030035030795261264 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00030272910953499377 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002721834753174335 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003115838917437941 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002512925711926073 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002752721484284848 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00028523890068754554 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00029511796310544014 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003051877720281482 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0003191052528563887 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.0002861747348170483\n",
            "Validation loss for fold 1: 0.00029178748649669515\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003870486107189208 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003516660653986037 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00036695876042358577 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00034508807584643364 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003484124899841845 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.000322688661981374 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00034583904198370874 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003572299610823393 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003004499594680965 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.000353973446181044 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003309311287011951 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003166387905366719 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003144411602988839 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00030764206894673407 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00027642014902085066 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003081230097450316 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00029279474983923137 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00027681965730153024 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00032092633773572743 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00030307806446217 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002852324687410146 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002708538668230176 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00028275884687900543 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002907328016590327 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00030533518292941153 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00026290444657206535 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00027900454006157815 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002851365425158292 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00027848739409819245 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00028948209364898503 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.00028376663565405545\n",
            "Validation loss for fold 2: 0.0002892754018336188\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003804243460763246 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.000384468148695305 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00034426181809976697 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003704293048940599 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003555423754733056 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003404170274734497 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00033945334143936634 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003300017851870507 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003294358612038195 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00030301031074486673 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003084323543589562 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00030795196653343737 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003138117026537657 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003206004330422729 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00032526071299798787 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00029572771745733917 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002877491933759302 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00030091547523625195 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003080654132645577 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002973895170725882 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00027732839225791395 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002806112461257726 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002701523480936885 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00029190845089033246 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00028323999140411615 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002896939404308796 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00029849083512090147 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.000294676108751446 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002902875130530447 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00030033980146981776 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.00028527811560851725\n",
            "Validation loss for fold 3: 0.00028773842548363764\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00035835980088450015 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003850230423267931 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00037328293547034264 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00035323190968483686 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00035109929740428925 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00034799077548086643 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00036887614987790585 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00033965439070016146 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00033850304316729307 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00036018670652993023 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00032282518805004656 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002986671170219779 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003421278961468488 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003102553600911051 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00029324021306820214 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003224114188924432 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00033375504426658154 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00027506318292580545 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002953174407593906 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00027509010396897793 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00029502055258490145 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002946143795270473 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002794255269691348 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00029646631446667016 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002902595733758062 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0002818519715219736 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002632230462040752 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.000304757704725489 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002990162174683064 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00026972644263878465 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.00028177673247494845\n",
            "Validation loss for fold 4: 0.0002900539077684904\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.00028021843052508747\n",
            "Training Fold 1 Loss: 0.0002861747348170483\n",
            "Training Fold 2 Loss: 0.00028376663565405545\n",
            "Training Fold 3 Loss: 0.00028527811560851725\n",
            "Training Fold 4 Loss: 0.00028177673247494845\n",
            "Trainig Average Loss: 0.00028344292981593135\n",
            "Validation Fold 0 Loss: 0.00028437003079081043 \n",
            "Validation Fold 1 Loss: 0.00029178748649669515 \n",
            "Validation Fold 2 Loss: 0.0002892754018336188 \n",
            "Validation Fold 3 Loss: 0.00028773842548363764 \n",
            "Validation Fold 4 Loss: 0.0002900539077684904 \n",
            "Vaidation Average Loss: 0.00028864505047465047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q-MjpciX4LIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_4_3 = train_VAE_model(net=net3_4,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.7)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL85cnBIMqFn",
        "outputId": "857caeea-497e-454a-b933-fb8646118c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003777122183237225 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00037192305899225175 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00033986964263021946 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00036443062708713114 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00033346834243275225 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00035322076291777194 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003452979144640267 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00032715260749682784 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00034449793747626245 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003431514778640121 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003267342981416732 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003439878055360168 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003332607157062739 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003403282316867262 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00035715929698199034 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003435582621023059 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00034887102083303034 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003697253414429724 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00031456127180717885 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00032294337870553136 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0003226251865271479 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00031264725839719176 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00032481877133250237 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003462826134636998 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00031808874337002635 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00033106215414591134 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002929997572209686 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003216685145162046 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.000323309883242473 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0003441459557507187 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.00032833312768273373\n",
            "Validation loss for fold 0: 0.0003363099041244617\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00036846441798843443 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003536222211550921 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00037478411104530096 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.000370881927665323 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003503117186482996 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.000356576667400077 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003367825993336737 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003776599478442222 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00034477136796340346 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003217579214833677 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00034975982271134853 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003500853490550071 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003206408873666078 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00031052069971337914 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.000330407201545313 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00034625292755663395 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003431008371990174 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003273213224019855 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00033041593269445 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00034451342071406543 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00033205977524630725 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003242128877900541 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003562126657925546 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00034106624661944807 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00035252992529422045 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00031272548949345946 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00034983811201527715 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003425384929869324 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002987425832543522 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00031798932468518615 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.00032963793204097676\n",
            "Validation loss for fold 1: 0.0003336475743705737\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00037443762994371355 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00037751332274638116 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00034882870386354625 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003783339343499392 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003462494059931487 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00037633185274899006 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.000370906840544194 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003536006552167237 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00037929887184873223 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00035061457310803235 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00034025555942207575 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00037534110015258193 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003151106648147106 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003351854102220386 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00037741154665127397 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00035397865576669574 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00035379629116505384 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003173977311234921 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00037073635030537844 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0003796540549956262 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0003297879593446851 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003415932587813586 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00034022657200694084 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00033867807360365987 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0003568112151697278 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00035877327900379896 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00035775723517872393 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003592616703826934 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00035009137354791164 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0003445761976763606 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.00034283346800730496\n",
            "Validation loss for fold 2: 0.0003455783610310648\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003557789314072579 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00036685357918031514 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003415087703615427 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003522445331327617 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003419489657972008 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00036872870987281203 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00032910157460719347 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00033550249645486474 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003376813547220081 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.000321187952067703 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003582951321732253 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003337389207445085 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00036947790067642927 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003639925562310964 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00034125178353860974 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00035824411315843463 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003514669369906187 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003480716550257057 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003225881664548069 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00034002197207883 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0003490608942229301 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003531625843606889 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003725645365193486 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003109068493358791 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00032135844230651855 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.000352340517565608 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0003398176922928542 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00033630034886300564 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00031046324875205755 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00032459295471198857 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.00034224784915051407\n",
            "Validation loss for fold 3: 0.0003447068861149728\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=4, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=4, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003971302357967943 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003484063781797886 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.000393521913792938 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003521106846164912 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003695449559018016 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00035531679168343544 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003583021170925349 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003329127503093332 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.000375598669052124 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00033607869409024715 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003632819571066648 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00034362851874902844 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003592197026591748 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003520905156619847 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.000307132228044793 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00034415669506415725 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003425987670198083 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003434390528127551 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00034755264641717076 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0003218560595996678 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.000361371785402298 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003239947836846113 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00033759765210561454 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00034753046929836273 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0003629922866821289 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003389941994100809 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.000346507178619504 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003497219877317548 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003407385083846748 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00033273492590524256 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.0003422204659819559\n",
            "Validation loss for fold 4: 0.0003481817426109114\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.00032833312768273373\n",
            "Training Fold 1 Loss: 0.00032963793204097676\n",
            "Training Fold 2 Loss: 0.00034283346800730496\n",
            "Training Fold 3 Loss: 0.00034224784915051407\n",
            "Training Fold 4 Loss: 0.0003422204659819559\n",
            "Trainig Average Loss: 0.0003370545685726971\n",
            "Validation Fold 0 Loss: 0.0003363099041244617 \n",
            "Validation Fold 1 Loss: 0.0003336475743705737 \n",
            "Validation Fold 2 Loss: 0.0003455783610310648 \n",
            "Validation Fold 3 Loss: 0.0003447068861149728 \n",
            "Validation Fold 4 Loss: 0.0003481817426109114 \n",
            "Vaidation Average Loss: 0.00034168489365039693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_15_3 = train_VAE_model(net=net3_15,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azl5a37SMqFs",
        "outputId": "9ace052a-73e3-48ee-87ff-321c622f1e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00040442385943606496 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00039641791954636574 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00041654595406726 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003549403918441385 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00036350838490761817 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00035342684714123607 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003643675008788705 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003204151871614158 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003516322758514434 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00033449335023760796 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003326263395138085 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003356746456120163 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00032427330734208226 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003382190188858658 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00033202298800460994 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003352806088514626 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00033263638033531606 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003080673632211983 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003202013613190502 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0003015591064468026 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00033128680661320686 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00030872580828145146 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002902149280998856 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00027612445410341024 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0003169293631799519 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00030217261519283056 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00029223470482975245 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00030359343509189785 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002937739191111177 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0003123217320535332 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.0002990811013807201\n",
            "Validation loss for fold 0: 0.0003002800041874574\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003797327808570117 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00038109987508505583 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003773109056055546 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003613240842241794 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00034130769199691713 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00032658420968800783 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00035077944630756974 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00031340174609795213 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.000321112951496616 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003102064656559378 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00031729310285300016 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0002953294606413692 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00030763543327338994 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003361827984917909 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0003202754887752235 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002868984011001885 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003284469130448997 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00031939195469021797 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002844379923772067 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0003202581428922713 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.000309390394249931 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00032128836028277874 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.000326604931615293 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003168884722981602 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002939770638477057 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.000312356511130929 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00030978419817984104 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00029765276121906936 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003205473767593503 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002943621657323092 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.00030420479166921963\n",
            "Validation loss for fold 1: 0.00030691953330370475\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00037603461532853544 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00036365733831189573 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003725681162904948 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00038405321538448334 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003625147510319948 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003238299104850739 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00030187974334694445 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003631887084338814 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.000353608833393082 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003033303073607385 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00030031317146494985 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00032879208447411656 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.000294467929052189 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00031006624340079725 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00031190019217319787 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003445572510827333 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002948965411633253 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00030932246590964496 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003135270089842379 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00030283789965324104 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00031048848177306354 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00031065166695043445 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003057875146623701 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003045758348889649 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002967867476399988 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00029279207228682935 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0003074879350606352 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002978932170663029 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002771008003037423 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002974658855237067 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.00030182369128157273\n",
            "Validation loss for fold 2: 0.0003065334571779054\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003975279105361551 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.000380975310690701 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003138831234537065 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00034097759635187685 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00034341789432801306 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00033419797546230257 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00035567209124565125 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003704617265611887 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.000331479765009135 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00035168486647307873 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003280451928731054 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003063839685637504 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00035691476659849286 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00032197829568758607 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00031729001784697175 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003223658713977784 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00033802184043452144 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003479103615973145 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00031396327540278435 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0003353823267389089 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0003144600777886808 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002854185295291245 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002951657515950501 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002895049983635545 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.000300824292935431 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003076022258028388 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.000303427514154464 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002953908406198025 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003075592394452542 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0003032242238987237 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.00030834939327939595\n",
            "Validation loss for fold 3: 0.0003120005931608583\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=15, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=15, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00036164961056783795 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003625528479460627 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00035701715387403965 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00036126235499978065 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00034237682120874524 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003327261656522751 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003446268674451858 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00033721752697601914 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003190085990354419 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003362970019225031 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00032204118906520307 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003115144791081548 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00029743058257736266 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00032814437872730196 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.000342768122209236 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00030384515412151814 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002914206706918776 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.000321415311191231 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003181042557116598 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0003055182460229844 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002942699065897614 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00029686023481190205 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00032945649581961334 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00030486081959679723 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00031257153023034334 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003049045044463128 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002893487107940018 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003133517748210579 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003143184876535088 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0003223026287741959 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.00030274214239136096\n",
            "Validation loss for fold 4: 0.0003104968836314007\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.0002990811013807201\n",
            "Training Fold 1 Loss: 0.00030420479166921963\n",
            "Training Fold 2 Loss: 0.00030182369128157273\n",
            "Training Fold 3 Loss: 0.00030834939327939595\n",
            "Training Fold 4 Loss: 0.00030274214239136096\n",
            "Trainig Average Loss: 0.0003032402240004539\n",
            "Validation Fold 0 Loss: 0.0003002800041874574 \n",
            "Validation Fold 1 Loss: 0.00030691953330370475 \n",
            "Validation Fold 2 Loss: 0.0003065334571779054 \n",
            "Validation Fold 3 Loss: 0.0003120005931608583 \n",
            "Validation Fold 4 Loss: 0.0003104968836314007 \n",
            "Vaidation Average Loss: 0.0003072460942922653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_25_3 = train_VAE_model(net=net3_25,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87vrj17zMqFt",
        "outputId": "2be17579-7e46-41dc-fb57-ba5c8f2fc5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00039085213211365044 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003792324278037995 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003708626900333911 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.000364038540283218 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00033392099430784583 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00034888071240857244 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003355742373969406 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003489648224785924 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003457074926700443 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003628631529863924 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00033250130945816636 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003307224833406508 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003188819973729551 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003213518939446658 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00032073346665129066 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003028276260010898 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003136652521789074 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003047462669201195 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0002963511215057224 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.000311259034788236 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0002970112836919725 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003271120076533407 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003151416312903166 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003079392190556973 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0003163715882692486 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003130401310045272 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.000304835062706843 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00030243126093409956 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003161421627737582 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0003192858421243727 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.00030288695138393684\n",
            "Validation loss for fold 0: 0.0003105567430850456\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00038718542782589793 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003769166942220181 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003454164834693074 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003549357352312654 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00034987658727914095 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00032552360789850354 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003631282888818532 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003422476875130087 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00033690722193568945 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003295177884865552 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0002984206657856703 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00030178585438989103 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00031494826544076204 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00031067346571944654 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00031750285415910184 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00033736578188836575 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003022993041668087 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003453613317105919 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003172381257172674 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002823126851581037 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0003271791210863739 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0002772207371890545 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002923630236182362 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003096272121183574 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002916025114245713 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00030056454124860466 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002905018627643585 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003052027022931725 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00029340057517401874 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00030010068439878523 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.0002985752313523679\n",
            "Validation loss for fold 1: 0.0003017212510705436\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003768906171899289 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00037435375270433724 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003484521002974361 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003355442313477397 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00033015318331308663 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00034044351195916533 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00034549759584479034 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003354632935952395 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003127084346488118 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003598028561100364 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003210180439054966 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00032191735226660967 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0002891914627980441 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.000308854941977188 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0002942649298347533 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003149916010443121 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00031739124096930027 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00030644857906736434 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00029107838054187596 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00029498818912543356 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00028794127865694463 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003116689622402191 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003036447160411626 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003039261791855097 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00033012666972354054 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00030859559774398804 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0003246166743338108 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00032269119401462376 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00030781474197283387 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002984232851304114 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.00030021353750615506\n",
            "Validation loss for fold 2: 0.00030029760381381306\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003839957353193313 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00038068610592745245 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003698311047628522 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.000356509379344061 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00033190386602655053 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003666587872430682 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00034115120070055127 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003326178702991456 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003368564648553729 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003317748778499663 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003209110873285681 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003420044668018818 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003221551887691021 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003159005136694759 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00031433021649718285 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002924845030065626 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00028428237419575453 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00031388350180350244 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003193771408405155 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0003311596519779414 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00029433879535645247 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00031772832153365016 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003005559556186199 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00029989745235070586 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00032870733411982656 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00029495390481315553 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0003055869019590318 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003030959633179009 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00030085426988080144 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00029775575967505574 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.0003027678530188601\n",
            "Validation loss for fold 3: 0.00030847083733925444\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=25, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=25, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00041463159141130745 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003654292959254235 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003360902483109385 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00036076761898584664 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00033976181293837726 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003686623240355402 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003348943137098104 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003206893161404878 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00034019292797893286 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003201052895747125 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00032707228092476726 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00031266259611584246 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.000321227969834581 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00033632456324994564 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00033971978700719774 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0002904097782447934 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00032442063093185425 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003278701624367386 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00028339066193439066 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00030704549863003194 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00032602023566141725 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00030477691325359046 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00028203416150063276 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0003025878104381263 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00029358165920712054 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00033069562050513923 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0003114130813628435 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00030156687716953456 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00030200264882296324 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.000292319426080212 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.0003002211660945713\n",
            "Validation loss for fold 4: 0.0003046192814308649\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.00030288695138393684\n",
            "Training Fold 1 Loss: 0.0002985752313523679\n",
            "Training Fold 2 Loss: 0.00030021353750615506\n",
            "Training Fold 3 Loss: 0.0003027678530188601\n",
            "Training Fold 4 Loss: 0.0003002211660945713\n",
            "Trainig Average Loss: 0.0003009329478711782\n",
            "Validation Fold 0 Loss: 0.0003105567430850456 \n",
            "Validation Fold 1 Loss: 0.0003017212510705436 \n",
            "Validation Fold 2 Loss: 0.00030029760381381306 \n",
            "Validation Fold 3 Loss: 0.00030847083733925444 \n",
            "Validation Fold 4 Loss: 0.0003046192814308649 \n",
            "Vaidation Average Loss: 0.00030513314334790437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_50_3 = train_VAE_model(net=net3_50,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0YVrKJWMqFt",
        "outputId": "295674f7-a422-48eb-f0e2-2f484e95fdd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003718934895005077 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003857279953081161 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003666273260023445 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003859947028104216 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00036405102582648396 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00035628408659249544 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003229234425816685 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00036753539461642504 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00035378997563384473 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003648139536380768 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00033102554152719676 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00032307623769156635 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00031024980125948787 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003377589164301753 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0003258177894167602 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00032638030825182796 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003149767580907792 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00031701126135885715 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00030645146034657955 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00032723607728257775 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0003127465897705406 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00029730494134128094 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0002931532508227974 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00030570043600164354 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00030624170904047787 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.000300315412459895 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002890043251682073 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003065504424739629 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00029217381961643696 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0003104659845121205 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.00029944960767237837\n",
            "Validation loss for fold 0: 0.00030432920879954785\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00039145653136074543 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00037943359347991645 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00036827786243520677 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00034453533589839935 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003670270671136677 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00037587768747471273 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003501680912449956 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003574503061827272 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00033661662018857896 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003497013240121305 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00031084963120520115 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003140430198982358 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00031521718483418226 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00030696281464770436 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0003141719789709896 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00030837440863251686 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00033283073571510613 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00033424660796299577 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00031127376132644713 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00031832788954488933 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00031805396429263055 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003255818737670779 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003422597364988178 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002970347704831511 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0003065210476052016 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00031252807821147144 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00033154766424559057 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00029773369897156954 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0002669495588634163 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.000308318471070379 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.0002962100646210453\n",
            "Validation loss for fold 1: 0.0003002081038754812\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003832886868622154 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00037051134859211743 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003624684759415686 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003359155380167067 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00035573533386923373 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.0003460382577031851 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003501475730445236 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003370692429598421 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00037478673039004207 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00032359908800572157 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00032729352824389935 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003396926331333816 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003285088750999421 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003452014352660626 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0003318967064842582 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003381810965947807 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00031378562562167645 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003101350157521665 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003009679785463959 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0002930289483629167 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0003163366636727005 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003158111940138042 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00031113956356421113 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00028523069340735674 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00031689851311966777 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003083061892539263 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00032982605625875294 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003017258131876588 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003100135363638401 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00029278811416588724 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.0003035887003405214\n",
            "Validation loss for fold 2: 0.0003050916064424753\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003806352324318141 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00038132001645863056 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003772036579903215 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003542977210599929 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00035877845948562026 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00034046670771203935 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00032233147067017853 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00035010158899240196 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00034427375067025423 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00034423405304551125 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003358932153787464 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00033093226375058293 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00032605099841021 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003369332698639482 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0003108505916316062 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00032439996721222997 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00033720998908393085 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00034170868457295 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00030811529722996056 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00031930857221595943 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0003121139598079026 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00029550809995271266 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00030917630647309124 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00029856993933208287 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00030968873761594296 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003237960336264223 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00030653137946501374 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003241199301555753 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003027830389328301 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00028585176914930344 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.0003014272979557744\n",
            "Validation loss for fold 3: 0.0003097338943915041\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=50, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=50, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00039787113200873137 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.000395541253965348 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003747929586097598 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00036648206878453493 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00035140468389727175 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00032730240491218865 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003543771163094789 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003479231963865459 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003583832294680178 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.0003270922461524606 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00032986505539156497 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003246135311201215 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00031181939993984997 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003341594128869474 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.000339061749400571 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00031234839116223156 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0003138994215987623 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003099794266745448 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00029351585544645786 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00029343165806494653 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00031422669417224824 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00032174488296732306 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.000302577274851501 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00029478748911060393 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.00032398494658991694 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003109124081674963 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0003123700444120914 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003133136488031596 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003235865733586252 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.000304311397485435 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.0003034155688119474\n",
            "Validation loss for fold 4: 0.00031231755355549555\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.00029944960767237837\n",
            "Training Fold 1 Loss: 0.0002962100646210453\n",
            "Training Fold 2 Loss: 0.0003035887003405214\n",
            "Training Fold 3 Loss: 0.0003014272979557744\n",
            "Training Fold 4 Loss: 0.0003034155688119474\n",
            "Trainig Average Loss: 0.0003008182478803334\n",
            "Validation Fold 0 Loss: 0.00030432920879954785 \n",
            "Validation Fold 1 Loss: 0.0003002081038754812 \n",
            "Validation Fold 2 Loss: 0.0003050916064424753 \n",
            "Validation Fold 3 Loss: 0.0003097338943915041 \n",
            "Validation Fold 4 Loss: 0.00031231755355549555 \n",
            "Vaidation Average Loss: 0.0003063360734129008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_outputs_100_3 = train_VAE_model(net=net3_100,\n",
        "                                 dataset=dataset,\n",
        "                                 k=k, \n",
        "                                 epochs=epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 beta = 0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZn2DD9lMqFu",
        "outputId": "1bfff461-9320-423e-ae1c-037f8501d206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0004068537091370672 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003909691877197474 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00035331814433448017 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003426764451432973 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00034701323602348566 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00037241860991343856 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003776575031224638 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003390028141438961 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003323607670608908 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00033475819509476423 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00035966679570265114 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003351651830598712 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003228390996810049 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003296943905297667 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.0003185705281794071 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.000327302172081545 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00032189287594519556 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003143985813949257 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00033040865673683584 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00032676069531589746 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.0003039762668777257 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00032730892417021096 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.000328849971992895 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00030595273710787296 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002867328003048897 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00030799114028923213 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.00030209842952899635 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.00030004334985278547 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00029229576466605067 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0002941926650237292 Training process has finished. Saving trained model.\n",
            "Training loss for fold 0: 0.00030705118524521936\n",
            "Validation loss for fold 0: 0.00031013287740090114\n",
            "--------------------------------\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00038556510116904974 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003895832342095673 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003845184692181647 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003367084136698395 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00031196544296108186 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.000347582739777863 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00036169373197481036 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00033243148936890066 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.000315517041599378 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00032486466807313263 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003215002652723342 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003232106100767851 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00031501881312578917 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00033620744943618774 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00035336767905391753 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.000300547486403957 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00032020994694903493 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00034396920818835497 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003084576746914536 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00032828786061145365 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00033154513221234083 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003171549178659916 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003082535695284605 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.0002910869079641998 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002957252727355808 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00030817798688076437 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0002940526755992323 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003032547247130424 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00029049423756077886 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00028000512975268066 Training process has finished. Saving trained model.\n",
            "Training loss for fold 1: 0.00030246512125817963\n",
            "Validation loss for fold 1: 0.00030371739821564216\n",
            "--------------------------------\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00040495285065844655 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.0003654747561085969 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00032420959905721247 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003700524684973061 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00036095650284551084 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00036072329385206103 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00033717002952471375 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.00033186908694915473 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003452161035966128 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00033091267687268555 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.00033419535611756146 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.00034411551314406097 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003173747973050922 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.0003371042257640511 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00031407750793732703 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00032191607169806957 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.0002894919889513403 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003345478617120534 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.00030117982532829046 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00031939303153194487 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00028856322751380503 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.000315173645503819 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00032990064937621355 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00030617049196735024 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.000274623220320791 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003041369782295078 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0003000799042638391 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002863829140551388 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00032772720442153513 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0003284442063886672 Training process has finished. Saving trained model.\n",
            "Training loss for fold 2: 0.0003022307635044039\n",
            "Validation loss for fold 2: 0.00031141097230957793\n",
            "--------------------------------\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.00037968027754686773 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00037957742461003363 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.00034929506364278495 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.00036445644218474627 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.0003520588215906173 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00036071264185011387 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.0003494821139611304 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.0003346079611219466 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.0003332988708280027 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.000326271983794868 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003345685836393386 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003287720319349319 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.0003243685932829976 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.00030865060398355126 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.000344707106705755 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.0003040515002794564 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00029985318542458117 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.0003003916353918612 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003120536857750267 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.00029613060178235173 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00034024525666609406 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.0003057504945900291 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.0003012171946465969 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00030184254865162075 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002858721127267927 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.0003257784992456436 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.000292683340376243 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0002816503692883998 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.00029788908432237804 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.00030476541724056005 Training process has finished. Saving trained model.\n",
            "Training loss for fold 3: 0.00030327212637916033\n",
            "Validation loss for fold 3: 0.0003091529051308164\n",
            "--------------------------------\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=204, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=128, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=196, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=196, out_features=204, bias=True)\n",
            "\n",
            " Epoch 1\n",
            "[200/128] batch loss: 0.0003851483343169093 \n",
            " Epoch 2\n",
            "[200/128] batch loss: 0.00038371654227375984 \n",
            " Epoch 3\n",
            "[200/128] batch loss: 0.0003591105341911316 \n",
            " Epoch 4\n",
            "[200/128] batch loss: 0.0003530319081619382 \n",
            " Epoch 5\n",
            "[200/128] batch loss: 0.00035318429581820965 \n",
            " Epoch 6\n",
            "[200/128] batch loss: 0.00031991887954063714 \n",
            " Epoch 7\n",
            "[200/128] batch loss: 0.00035787082742899656 \n",
            " Epoch 8\n",
            "[200/128] batch loss: 0.000370048830518499 \n",
            " Epoch 9\n",
            "[200/128] batch loss: 0.00035425700480118394 \n",
            " Epoch 10\n",
            "[200/128] batch loss: 0.00032330595422536135 \n",
            " Epoch 11\n",
            "[200/128] batch loss: 0.0003370481717865914 \n",
            " Epoch 12\n",
            "[200/128] batch loss: 0.0003233497263863683 \n",
            " Epoch 13\n",
            "[200/128] batch loss: 0.00032044691033661366 \n",
            " Epoch 14\n",
            "[200/128] batch loss: 0.000324517663102597 \n",
            " Epoch 15\n",
            "[200/128] batch loss: 0.00033734060707502067 \n",
            " Epoch 16\n",
            "[200/128] batch loss: 0.00034335561213083565 \n",
            " Epoch 17\n",
            "[200/128] batch loss: 0.00031437299912795424 \n",
            " Epoch 18\n",
            "[200/128] batch loss: 0.00032477054628543556 \n",
            " Epoch 19\n",
            "[200/128] batch loss: 0.0003233386087231338 \n",
            " Epoch 20\n",
            "[200/128] batch loss: 0.0003297909570392221 \n",
            " Epoch 21\n",
            "[200/128] batch loss: 0.00030762431561015546 \n",
            " Epoch 22\n",
            "[200/128] batch loss: 0.00033573186374269426 \n",
            " Epoch 23\n",
            "[200/128] batch loss: 0.00031529724947176874 \n",
            " Epoch 24\n",
            "[200/128] batch loss: 0.00031207012943923473 \n",
            " Epoch 25\n",
            "[200/128] batch loss: 0.0002933839859906584 \n",
            " Epoch 26\n",
            "[200/128] batch loss: 0.00028694068896584213 \n",
            " Epoch 27\n",
            "[200/128] batch loss: 0.0003048668149858713 \n",
            " Epoch 28\n",
            "[200/128] batch loss: 0.0003355288354214281 \n",
            " Epoch 29\n",
            "[200/128] batch loss: 0.0003142804780509323 \n",
            " Epoch 30\n",
            "[200/128] batch loss: 0.0003070405509788543 Training process has finished. Saving trained model.\n",
            "Training loss for fold 4: 0.00030552059635685673\n",
            "Validation loss for fold 4: 0.00031098718532272134\n",
            "--------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Training Fold 0 Loss: 0.00030705118524521936\n",
            "Training Fold 1 Loss: 0.00030246512125817963\n",
            "Training Fold 2 Loss: 0.0003022307635044039\n",
            "Training Fold 3 Loss: 0.00030327212637916033\n",
            "Training Fold 4 Loss: 0.00030552059635685673\n",
            "Trainig Average Loss: 0.000304107958548764\n",
            "Validation Fold 0 Loss: 0.00031013287740090114 \n",
            "Validation Fold 1 Loss: 0.00030371739821564216 \n",
            "Validation Fold 2 Loss: 0.00031141097230957793 \n",
            "Validation Fold 3 Loss: 0.0003091529051308164 \n",
            "Validation Fold 4 Loss: 0.00031098718532272134 \n",
            "Vaidation Average Loss: 0.0003090802676759318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAE_avg_train_loss_1 = []\n",
        "VAE_avg_val_loss_1  = []\n",
        "VAE_trained_models_1 = [full_outputs_4_1 ,\n",
        "                  full_outputs_15_1 ,\n",
        "                  full_outputs_25_1 ,\n",
        "                  full_outputs_50_1,\n",
        "                  full_outputs_100_1 ]\n"
      ],
      "metadata": {
        "id": "5FsVPnzHGRcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VAE_avg_train_loss_2 = []\n",
        "VAE_avg_val_loss_2  = []\n",
        "VAE_trained_models_2 = [full_outputs_4_2 ,\n",
        "                  full_outputs_15_2 ,\n",
        "                  full_outputs_25_2 ,\n",
        "                  full_outputs_50_2,\n",
        "                  full_outputs_100_2 ]"
      ],
      "metadata": {
        "id": "5FcHMiK_4nrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VAE_avg_train_loss_3 = []\n",
        "VAE_avg_val_loss_3  = []\n",
        "VAE_trained_models_3 = [full_outputs_4_3 ,\n",
        "                  full_outputs_15_3 ,\n",
        "                  full_outputs_25_3 ,\n",
        "                  full_outputs_50_3,\n",
        "                  full_outputs_100_3 ]"
      ],
      "metadata": {
        "id": "QEYfygGGNOVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "'''# Open a file and use dump()\n",
        "with open('VAE_trained_models_1.pkl', 'wb') as file:\n",
        "      \n",
        "    # A new file will be created\n",
        "    pickle.dump(VAE_trained_models_1, file)'''"
      ],
      "metadata": {
        "id": "0ukqjxQ4hPyO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "70ee60de-b25b-4590-8ba0-b613f14db2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"# Open a file and use dump()\\nwith open('VAE_trained_models_1.pkl', 'wb') as file:\\n      \\n    # A new file will be created\\n    pickle.dump(VAE_trained_models_1, file)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''# Open a file and use dump()\n",
        "with open('VAE_trained_models_2.pkl', 'wb') as file:\n",
        "      \n",
        "    # A new file will be created\n",
        "    pickle.dump(VAE_trained_models_2, file)'''"
      ],
      "metadata": {
        "id": "EmE_0wI_h-E1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "42ebdbfb-dbc4-44cd-e357-fb2863a7b0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"# Open a file and use dump()\\nwith open('VAE_trained_models_2.pkl', 'wb') as file:\\n      \\n    # A new file will be created\\n    pickle.dump(VAE_trained_models_2, file)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''# Open a file and use dump()\n",
        "with open('VAE_trained_models_3.pkl', 'wb') as file:\n",
        "      \n",
        "    # A new file will be created\n",
        "    pickle.dump(VAE_trained_models_3, file)'''"
      ],
      "metadata": {
        "id": "s3Sw3ocaiAdg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6f00ed53-7558-4b8c-f371-5cffd5c27ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"# Open a file and use dump()\\nwith open('VAE_trained_models_3.pkl', 'wb') as file:\\n      \\n    # A new file will be created\\n    pickle.dump(VAE_trained_models_3, file)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file in binary mode\n",
        "with open('VAE_trained_models_1.pkl', 'rb') as file:\n",
        "      \n",
        "    # Call load method to deserialze\n",
        "    VAE_trained_models_1 = pickle.load(file)\n",
        "  \n",
        "    print(VAE_trained_models_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "ijHS6WqXR9-J",
        "outputId": "f6b57801-a0db-43d5-fed7-9e6606e54a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-9a79417de480>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Open the file in binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VAE_trained_models_1.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Call load method to deserialze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mVAE_trained_models_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'VAE_trained_models_1.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file in binary mode\n",
        "with open('VAE_trained_models_2.pkl', 'rb') as file:\n",
        "      \n",
        "    # Call load method to deserialze\n",
        "    VAE_trained_models_2 = pickle.load(file)\n",
        "  \n",
        "    print(VAE_trained_models_2)"
      ],
      "metadata": {
        "id": "dIg3Qo-OSH2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file in binary mode\n",
        "with open('VAE_trained_models_3.pkl', 'rb') as file:\n",
        "      \n",
        "    # Call load method to deserialze\n",
        "    VAE_trained_models_3 = pickle.load(file)\n",
        "  \n",
        "    print(VAE_trained_models_3)"
      ],
      "metadata": {
        "id": "VSjdvIjsSvUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in VAE_trained_models_1:\n",
        "  VAE_avg_train_loss_1.append(model[0])\n",
        "  VAE_avg_val_loss_1.append(model[1])"
      ],
      "metadata": {
        "id": "8k8a7841Gys2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in VAE_trained_models_2:\n",
        "  VAE_avg_train_loss_2.append(model[0])\n",
        "  VAE_avg_val_loss_2.append(model[1])"
      ],
      "metadata": {
        "id": "7pgfJiju4u59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in VAE_trained_models_3:\n",
        "  VAE_avg_train_loss_3.append(model[0])\n",
        "  VAE_avg_val_loss_3.append(model[1])"
      ],
      "metadata": {
        "id": "Ete5pnI_NkJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data=[latent_size, VAE_avg_train_loss_1, VAE_avg_val_loss_1, VAE_avg_train_loss_2, VAE_avg_val_loss_2, VAE_avg_train_loss_3, VAE_avg_val_loss_3])\n",
        "\n",
        "df.columns = df.iloc[0]\n",
        "df = df[1:]\n",
        "\n",
        "df['Loss'] = ['Average training loss .2', 'Average validation loss .2', 'Average training loss .5', 'Average validation loss .5', 'Average training loss .7', 'Average validation loss .7']\n",
        "df = df.set_index('Loss')\n",
        "df"
      ],
      "metadata": {
        "id": "Xf_dkFuRRrKk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "df76d8e5-96c4-4335-fc7e-d17d4af91413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                4.0      15.0      25.0      50.0     100.0\n",
              "Loss                                                                        \n",
              "Average training loss .2    0.000315  0.000255  0.000236  0.000232  0.000232\n",
              "Average validation loss .2  0.000321  0.000261  0.000243  0.000238  0.000239\n",
              "Average training loss .5    0.000332  0.000289  0.000281  0.000280  0.000283\n",
              "Average validation loss .5  0.000337  0.000295  0.000285  0.000285  0.000289\n",
              "Average training loss .7    0.000337  0.000303  0.000301  0.000301  0.000304\n",
              "Average validation loss .7  0.000342  0.000307  0.000305  0.000306  0.000309"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10ea1aa5-a350-4bb8-a26f-1c458e1dd395\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>4.0</th>\n",
              "      <th>15.0</th>\n",
              "      <th>25.0</th>\n",
              "      <th>50.0</th>\n",
              "      <th>100.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loss</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Average training loss .2</th>\n",
              "      <td>0.000315</td>\n",
              "      <td>0.000255</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.000232</td>\n",
              "      <td>0.000232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average validation loss .2</th>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>0.000238</td>\n",
              "      <td>0.000239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average training loss .5</th>\n",
              "      <td>0.000332</td>\n",
              "      <td>0.000289</td>\n",
              "      <td>0.000281</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>0.000283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average validation loss .5</th>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.000295</td>\n",
              "      <td>0.000285</td>\n",
              "      <td>0.000285</td>\n",
              "      <td>0.000289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average training loss .7</th>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>0.000304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average validation loss .7</th>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>0.000309</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10ea1aa5-a350-4bb8-a26f-1c458e1dd395')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10ea1aa5-a350-4bb8-a26f-1c458e1dd395 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10ea1aa5-a350-4bb8-a26f-1c458e1dd395');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NsQr7ycvHJrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# transpose and plot\n",
        "ax = df.T.plot(figsize=(7, 6))\n",
        "ax.set_ylabel('MSE loss', fontsize=12)\n",
        "ax.set_xlabel('Latent Dimensions', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vIN1mWeqR4cA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "5761d41a-c46f-490a-a53f-2e7f178d2f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model in VAE_trained_models_1:\n",
        "  val_latents_df = pd.DataFrame(model[2])\n",
        "  plt.figure()\n",
        "  sb.heatmap(val_latents_df.corr(), cmap=\"RdBu\", vmin=-1, vmax=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DqQ010MVwNNv",
        "outputId": "012e2126-84aa-47c2-8989-844a882dc2c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model in VAE_trained_models_2:\n",
        "  val_latents_df = pd.DataFrame(model[2])\n",
        "  plt.figure()\n",
        "  sb.heatmap(val_latents_df.corr(), cmap=\"RdBu\", vmin=-1, vmax=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cryhm_b3wSUt",
        "outputId": "6e304b8d-52b0-47f5-9cc1-cb01247ccfe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model in VAE_trained_models_3:\n",
        "  val_latents_df = pd.DataFrame(model[2])\n",
        "  plt.figure()\n",
        "  sb.heatmap(val_latents_df.corr(), cmap=\"RdBu\", vmin=-1, vmax=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "73V3uzjRwS2W",
        "outputId": "9ce775cd-a0b6-48c1-eeed-74d7661d1cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD8CAYAAABTjp5OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAV10lEQVR4nO3df5BdZX3H8fdnNwmhUiSIgzFJIZa0iqUTagytzKiFANHpENpSDU5LVOg6HfBHGR3CMCMVtY1tR6w2VXdIMP4YwGKVrWLTEKBORTCrxpCExizRKRsjqQRIGfKD3fvtH/cJOWzv3Xs3927uPc9+XjPP7DnP+fE890747MNzztmjiMDMzLpfT6c7YGZmzXFgm5mVhAPbzKwkHNhmZiXhwDYzKwkHtplZSTiwzczqkLRW0l5JW+tsl6RPSxqStEXS7xS2rZC0M5UV7eiPA9vMrL4vAEvH2f4WYEEqfcBnASSdCtwEnAcsBm6SNKvVzjiwzczqiIjvAPvG2WUZ8MWoegg4RdJs4BJgQ0Tsi4ingA2MH/xNmdbqCRqZce67/Shlsv/B1Z3uQtcIqdNdsC504syZLf/DmEjmPL/5tvdQHRkf0R8R/RNobg7weGF9ONXVq2/JpAe2mVm3SuE8kYDuKE+JmFlW1NPbdGmD3cC8wvrcVFevviUObDPLSs+0GU2XNhgArkx3i/wu8ExE7AHWAxdLmpUuNl6c6lriKREzy0qbRs7Vc0m3A28GTpM0TPXOj+kAEfE54B7grcAQ8BzwrrRtn6SPApvSqW6OiPEuXjbFgW1mWVFv+wI7Iq5osD2Aa+psWwusbVtncGCbWWZ62jjC7jYObDPLSjunRLqNA9vMsuLANjMriZ5p0zvdhUnjwDazrHiEbWZWEg5sM7OSaOdtfd3GgW1mWfEI28ysJHrb88h5V3Jgm1lWPMI2MysJB7aZWUk4sM3MSsKBbWZWEg5sM7OS6Jnuu0TMzErBI2wzs5JwYJuZlURPjzrdhUnjl/CaWVbUo6ZLw3NJSyXtkDQkaWWN7bdI2pzKTyQ9Xdg2Wtg20I7P5hG2mWWlt7c941BJvcBq4CJgGNgkaSAith/ZJyL+srD/e4FzC6c4EBEL29KZxCNsM8tKG0fYi4GhiNgVEYeBO4Bl4+x/BXB7mz5GTQ1H2JJeTbWTc1LVbmAgIh6dzI6ZmR2LZqY6mjQHeLywPgycV7NN6QxgPnBfoXqmpEFgBFgVEd9otUPjjrAlXU/1t4qA76ci4PZa8zmF4/okDUoarPxyR6t9NDNrWo/UdClmVSp9x9jscuCuiBgt1J0REYuAdwCfkvTrrX62RiPsq4DXRsTzxUpJnwS2AatqHRQR/UA/wIxz3x2tdtLMrFkTGWEXs6qG3cC8wvrcVFfLcuCaMefenX7ukvQA1fntx5ruXA2N5rArwCtr1M9O28zMukob57A3AQskzZc0g2oo/7+7PdK08Szge4W6WZJOSMunAecD28ceO1GNRtgfADZK2snRuZxfA84Crm21cTOzduud1p457IgYkXQtsB7oBdZGxDZJNwODEXEkvJcDd0REcTbhNcDnJVWoDoxXFe8uOVbjBnZE/Juk36B6tbR40XHTmLkaM7OuILXvwZmIuAe4Z0zdh8es/1WN4x4EzmlbR5KGd4lERAV4qN0Nm5lNhpyfdPSDM2aWlTbe1td1HNhmlhUHtplZSfS0cQ672ziwzSwrPdPy/YsbDmwzy4ovOpqZlUQ7b+vrNg5sM8uK8p0RcWCbWV48JWJmVhI9bXqBQTdyYJtZVjzCNjMrCT84Y2ZWEr0ObDOzcnBgm5mVhAPbzKwkZvjRdDOzcpjmEbaZWTl4SsTMrCRyDux8J3vMbErq7elpujQiaamkHZKGJK2ssf2dkv5H0uZUri5sWyFpZyor2vHZPMI2s6y0a4QtqRdYDVwEDAObJA3UePv5nRFx7ZhjTwVuAhYBAfwgHftUK32a9MDe/+DqyW6iNE5+wzWd7kLX2P/dz3S6C90j5z8v1wFtvEtkMTAUEbsAJN0BLAPGBnYtlwAbImJfOnYDsBS4vZUO+V+KmWWlV2q6SOqTNFgofYVTzQEeL6wPp7qx/ljSFkl3SZo3wWMnxFMiZpaViUyJREQ/0N9Cc/8K3B4RhyS9B1gHXNDC+cblEbaZZaW3R02XBnYD8wrrc1PdCyLiyYg4lFZvBV7X7LHHwoFtZlmZ1qOmSwObgAWS5kuaASwHBoo7SJpdWL0UeDQtrwculjRL0izg4lTX2mdr9QRmZt2kXRcdI2JE0rVUg7YXWBsR2yTdDAxGxADwPkmXAiPAPuCd6dh9kj5KNfQBbj5yAbIVDmwzy0o7H5yJiHuAe8bUfbiwfANwQ51j1wJr29YZHNhmlpmcn3R0YJtZVhzYZmYl4cA2MysJB7aZWUn4BQZmZiXhEbaZWUn0yoFtZlYKPQ5sM7Ny6M03rx3YZpaXHs9hm5mVw/QmXv1VVg5sM8uKp0TMzErCUyJmZiXhu0TMzErCUyJmZiUxvdcXHc3MSsFTImZmJZHzlEi+/+9gZlNSj9R0aUTSUkk7JA1JWllj+3WStkvaImmjpDMK20YlbU5lYOyxx8IjbDPLSrv+Wp+kXmA1cBEwDGySNBAR2wu7/QhYFBHPSfoL4G+Bt6dtByJiYVs6k3iEbWZZ6VHzpYHFwFBE7IqIw8AdwLLiDhFxf0Q8l1YfAua2+/MUHXNgS3rXONv6JA1KGlyzZs2xNmFmNmHTe3qaLsWsSqWvcKo5wOOF9eFUV89VwLcL6zPTOR+SdFk7PlsrUyIfAW6rtSEi+oF+gIMHDkQLbZiZTchE7uorZlUrJP0psAh4U6H6jIjYLelVwH2SHomIx1ppZ9zAlrSl3ibg9FYaNjObDG28rW83MK+wPjfVvYikJcCNwJsi4tCR+ojYnX7ukvQAcC4weYFNNZQvAZ4a20fgwVYaNjObDG1848wmYIGk+VSDejnwjuIOks4FPg8sjYi9hfpZwHMRcUjSacD5VC9ItqRRYH8TOCkiNo/dkH5jmJl1lXaNsCNiRNK1wHqgF1gbEdsk3QwMRsQA8HfAScA/q9ruf0fEpcBrgM9LqlC9VrhqzN0lx0QRkzvF7Dnso05+wzWd7kLX2P/dz3S6C91DvlnriJknnthy2m75+TNNZ85vv/KlpXrMxvdhm1lWMn4y3YFtZnnpId/EdmCbWVY8wjYzK4mMXzjjwDazvHiEbWZWEm28D7vrOLDNLCueEjEzK4mM89qBbWZ58SvCzMxKIuO8dmCbWV5yftDfgW1mWWnXK8K6kQPbzLLiKREzs5LwlIiZWUko4yG2A9vMspLxFLYD28zy0uvANjMrh5ynRHKenzezKahHzZdGJC2VtEPSkKSVNbafIOnOtP1hSWcWtt2Q6ndIuqQtn60dJzEz6xaaQBn3PFIvsBp4C3A2cIWks8fsdhXwVEScBdwCfCIdezbVt6y/FlgK/FM6X0sc2GaWlR6p6dLAYmAoInZFxGHgDmDZmH2WAevS8l3AharOySwD7oiIQxHxU2Aona8lkz6HHRnPJ02U3xR+1Mnnv7fTXega+x9c3ekuZGUikSOpD+grVPVHRH9angM8Xtg2DJw35hQv7BMRI5KeAV6W6h8ac+yc5ntWmy86mllWVBltet8Uzv0Nd+wSDmwzy4qi0q5T7QbmFdbnprpa+wxLmga8FHiyyWMnzHPYZpaXqDRfxrcJWCBpvqQZVC8iDozZZwBYkZYvB+6LiEj1y9NdJPOBBcD3W/1oHmGbWV4i2nSaGJF0LbAe6AXWRsQ2STcDgxExAKwBviRpCNhHNdRJ+30V2A6MANdERPNzNXUo2vTh6jlw8ODkNlAiE5lby50vOh7li45HzTzxxJbvUji0f1/TmXPCyaeW6q4Ij7DNLCttnMPuOg5sM8tLZaTTPZg0Dmwzy4tH2GZmJVFxYJuZlYLnsM3MysKBbWZWEhnfPuvANrOseErEzKwsHNhmZiXhwDYzKwkHtplZOXgO28ysLEZ9l4iZWTl4hG1mVg6eEjEzKwsHtplZSTiwzcxKIuNH0/0SXjPLSow833RphaRTJW2QtDP9nFVjn4WSvidpm6Qtkt5e2PYFST+VtDmVhY3adGCbWV4qo82X1qwENkbEAmBjWh/rOeDKiHgtsBT4lKRTCts/FBELU9ncqMGGgS3p1ZIulHTSmPqljY41MzveYnS06dKiZcC6tLwOuOz/9SXiJxGxMy3/HNgLvPxYGxw3sCW9D7gbeC+wVdKywua/Hue4PkmDkgbXrFlzrH0zM5u4SqXpUsyqVPom0NLpEbEnLf8COH28nSUtBmYAjxWqP56mSm6RdEKjBhtddPxz4HUR8aykM4G7JJ0ZEf8A1H09fET0A/0ABw4ebPqV82ZmLZvAVEcxq2qRdC/wihqbbhxznpBUN+skzQa+BKyIeOE2lhuoBv2M1IfrgZvH62+jwO6JiGdTh34m6c1UQ/sMxglsM7NOafVi4ovOFbGk3jZJT0iaHRF7UiDvrbPfycC3gBsj4qHCuY+Mzg9Jug34YKP+NJrDfqJ45TKF9x8ApwHnNDq5mdnxFpXRpkuLBoAVaXkF1enjF5E0A/g68MWIuGvMttnpp6jOf29t1GCjwL6S6pD9BRExEhFXAm9sdHIzs+Pu+N0lsgq4SNJOYElaR9IiSbemfd5GNSvfWeP2va9IegR4hOog+GONGhx3SiQihsfZ9t1GJzczO+4qx+dJx4h4EriwRv0gcHVa/jLw5TrHXzDRNv2ko5llpQ2363UtB7aZ5SXjR9Md2GaWlXbeJdJtHNhmlhePsM3MSsKBbWZWDnGc7hLpBAe2meXFI2wzs3KI5w93uguTxoFtZnnxlIiZWUl4SsTMrBza8EedupYD28yy4rtEzMxKIkYd2GZmpVB5fqTTXZg0Dmwzy4pH2GZmJeHANjMriYr/HraZWTnkfJdIo3c6mpmVSoxWmi6tkHSqpA2Sdqafs+rsN1p4n+NAoX6+pIclDUm6M72wd1wObDPLSuX5kaZLi1YCGyNiAbAxrddyICIWpnJpof4TwC0RcRbwFHBVowYd2GaWlcpopenSomXAurS8Dris2QMlCbgAuGsix3sO+3iSfz8esf/B1Z3uQtc4+Q3XdLoLXePwj9a2fI6JTHVI6gP6ClX9EdHf5OGnR8SetPwL4PQ6+82UNAiMAKsi4hvAy4CnI+LIMH8YmNOoQQe2mWVlIoGdwrluQEu6F3hFjU03jjlPSIo6pzkjInZLehVwn6RHgGea7mSBA9vMstLOu0QiYkm9bZKekDQ7IvZImg3srXOO3ennLkkPAOcCXwNOkTQtjbLnArsb9cf/j25mWakcHmm6tGgAWJGWVwB3j91B0ixJJ6Tl04Dzge0REcD9wOXjHT+WA9vMslKpVJouLVoFXCRpJ7AkrSNpkaRb0z6vAQYl/ZhqQK+KiO1p2/XAdZKGqM5pr2nUoKdEzCwrx+vR9Ih4EriwRv0gcHVafhA4p87xu4DFE2nTgW1mWQk/mm5mVg45P5ruwDazrPiv9ZmZlcRo63d/dC0HtpllxVMiZmYl4SkRM7OSiNF6T4iXnwPbzLLShr/C17Uc2GaWlah4hG1mVgqjh/3gjJlZKXgO28ysJCoObDOzcvBtfWZmJVHxRUczs3LwRUczs5LwRUczs5JwYJuZlUTOTzr6nY5mlpWoRNOlFZJOlbRB0s70c1aNfX5f0uZCOSjpsrTtC5J+Wti2sFGbDmwzy0plNJouLVoJbIyIBcDGtP4iEXF/RCyMiIXABcBzwL8XdvnQke0RsblRg54SMbOsVI7fXSLLgDen5XXAA1TfhF7P5cC3I+K5Y22w4Qhb0mJJr0/LZ0u6TtJbj7VBM7PJdBxH2KdHxJ60/Avg9Ab7LwduH1P3cUlbJN0i6YRGDY4b2JJuAj4NfFbS3wD/CLwEWCnpxnGO65M0KGlwzZo1jfpgZtY2Uak0XYpZlUpf8VyS7pW0tUZZ9qI2IwKo+xtA0mzgHGB9ofoG4NXA64FTGX90DjSeErkcWAicQPU3yNyI2C/p74GHgY/XOigi+oF+gAMHD+Z7j42ZdZ2JjJyLWVVn+5J62yQ9IWl2ROxJgbx3nKbeBnw9Ip4vnPvI6PyQpNuADzbqb6MpkZGIGE1zLo9FxP7U0AEg33tnzKy0YjSaLi0aAFak5RXA3ePsewVjpkNSyCNJwGXA1kYNNgrsw5J+JS2/rtDQS3Fgm1kXitFK06VFq4CLJO0ElqR1JC2SdOuRnSSdCcwD/mPM8V+R9AjwCHAa8LFGDTaaEnljRBwCiIjip5vO0d8sZmZdY/Tw8RlLRsSTwIU16geBqwvrPwPm1Njvgom2OW5gHwnrGvW/BH450cbMzCZbJfK9bOb7sM0sK6MObDOzcsj4bz85sM0sLx5hm5mVxGG/ccbMrBw8JWJmVhKeEjEzKwmPsM3MSsKBbWZWEp4SMTMrCd8lYmZWEp4SMTMrCU+JmJmVhEfYZmYl4RG2mVlJ5PxmFQe2mWXFd4mYmZWEp0TMzEoi54uOjV7Ca2ZWKqMRTZdWSPoTSdskVSQtGme/pZJ2SBqStLJQP1/Sw6n+TkkzGrXpwDazrIxG86VFW4E/Ar5TbwdJvcBq4C3A2cAVks5Omz8B3BIRZwFPAVc1atCBbWZZOVyJpksrIuLRiNjRYLfFwFBE7IqIw8AdwDJJAi4A7kr7rQMua9TmpM9hnzhzpia7jWZI6ouI/k73oxv4uziqG76Lwz9a28nmX9AN30U7fC5+1nTmSOoD+gpV/W3+DuYAjxfWh4HzgJcBT0fESKF+TqOTTaURdl/jXaYMfxdH+bs4asp9FxHRHxGLCuVFYS3pXklba5Rlneiv7xIxM6sjIpa0eIrdwLzC+txU9yRwiqRpaZR9pH5cU2mEbWZ2vG0CFqQ7QmYAy4GBiAjgfuDytN8K4O5GJ5tKgV36ubk28ndxlL+Lo/xdTICkP5Q0DPwe8C1J61P9KyXdA5BGz9cC64FHga9GxLZ0iuuB6yQNUZ3TXtOwzcj4qSAzs5xMpRG2mVmpObDNzEoi+8Cu91joVCRpraS9krZ2ui+dJGmepPslbU+PFr+/033qFEkzJX1f0o/Td/GRTvfJ6st6Djs9FvoT4CKqN6ZvAq6IiO0d7ViHSHoj8CzwxYj4rU73p1MkzQZmR8QPJf0q8APgsqn47yI9cfeSiHhW0nTgP4H3R8RDHe6a1ZD7CLvmY6Ed7lPHRMR3gH2d7kenRcSeiPhhWv5fqlfvGz5llqOoejatTk8l31FcyeUe2LUeC52S/2FabZLOBM4FHu5sTzpHUq+kzcBeYENETNnvotvlHthmdUk6Cfga8IGI2N/p/nRKRIxGxEKqT9stljRlp8u6Xe6BXe+xUJvi0nzt14CvRMS/dLo/3SAinqb69N3STvfFass9sGs+FtrhPlmHpQtta4BHI+KTne5PJ0l6uaRT0vKJVC/Q/1dne2X1ZB3YDR4LnXIk3Q58D/hNScOSGv7B9EydD/wZcIGkzam8tdOd6pDZwP2StlAd4GyIiG92uE9WR9a39ZmZ5STrEbaZWU4c2GZmJeHANjMrCQe2mVlJOLDNzErCgW1mVhIObDOzkvg/1yMeDUe65YwAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
